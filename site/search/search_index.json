{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u81ea\u7136\u8bed\u8a00\u5904\u7406 \u00b6","title":"\u81ea\u7136\u8bed\u8a00\u5904\u7406"},{"location":"#_1","text":"","title":"\u81ea\u7136\u8bed\u8a00\u5904\u7406"},{"location":"bosonnlp/","text":"\u73bb\u68ee\u6570\u636e \u00b6 2018-12-27 \u88ab \ud83d\udc1c \u91d1\u670d\u6536\u8d2d","title":"\u73bb\u68ee\u6570\u636e"},{"location":"bosonnlp/#_1","text":"2018-12-27 \u88ab \ud83d\udc1c \u91d1\u670d\u6536\u8d2d","title":"\u73bb\u68ee\u6570\u636e"},{"location":"jieba/","text":"\u7ed3\u5df4\u5206\u8bcd \u00b6 jieba \u201c\u7ed3\u5df4\u201d\u4e2d\u6587\u5206\u8bcd\uff1a\u505a\u6700\u597d\u7684 Python \u4e2d\u6587\u5206\u8bcd\u7ec4\u4ef6 \u7279\u70b9 \u00b6 \u652f\u6301\u4e09\u79cd\u5206\u8bcd\u6a21\u5f0f\uff1a \u7cbe\u786e\u6a21\u5f0f\uff0c\u8bd5\u56fe\u5c06\u53e5\u5b50\u6700\u7cbe\u786e\u5730\u5207\u5f00\uff0c\u9002\u5408\u6587\u672c\u5206\u6790\uff1b \u5168\u6a21\u5f0f\uff0c\u628a\u53e5\u5b50\u4e2d\u6240\u6709\u7684\u53ef\u4ee5\u6210\u8bcd\u7684\u8bcd\u8bed\u90fd\u626b\u63cf\u51fa\u6765, \u901f\u5ea6\u975e\u5e38\u5feb\uff0c\u4f46\u662f\u4e0d\u80fd\u89e3\u51b3\u6b67\u4e49\uff1b \u641c\u7d22\u5f15\u64ce\u6a21\u5f0f\uff0c\u5728\u7cbe\u786e\u6a21\u5f0f\u7684\u57fa\u7840\u4e0a\uff0c\u5bf9\u957f\u8bcd\u518d\u6b21\u5207\u5206\uff0c\u63d0\u9ad8\u53ec\u56de\u7387\uff0c\u9002\u5408\u7528\u4e8e\u641c\u7d22\u5f15\u64ce\u5206\u8bcd\u3002 \u652f\u6301\u7e41\u4f53\u5206\u8bcd \u652f\u6301\u81ea\u5b9a\u4e49\u8bcd\u5178 MIT \u6388\u6743\u534f\u8bae \u7b97\u6cd5 \u00b6 \u57fa\u4e8e\u524d\u7f00\u8bcd\u5178\u5b9e\u73b0\u9ad8\u6548\u7684\u8bcd\u56fe\u626b\u63cf\uff0c\u751f\u6210\u53e5\u5b50\u4e2d\u6c49\u5b57\u6240\u6709\u53ef\u80fd\u6210\u8bcd\u60c5\u51b5\u6240\u6784\u6210\u7684 \u6709\u5411\u65e0\u73af\u56fe (DAG) \u91c7\u7528\u4e86\u52a8\u6001\u89c4\u5212\u67e5\u627e\u6700\u5927\u6982\u7387\u8def\u5f84, \u627e\u51fa\u57fa\u4e8e\u8bcd\u9891\u7684\u6700\u5927\u5207\u5206\u7ec4\u5408 \u5bf9\u4e8e\u672a\u767b\u5f55\u8bcd\uff0c\u91c7\u7528\u4e86\u57fa\u4e8e\u6c49\u5b57\u6210\u8bcd\u80fd\u529b\u7684 HMM \u6a21\u578b\uff0c\u4f7f\u7528\u4e86 Viterbi \u7b97\u6cd5","title":"\u7ed3\u5df4\u5206\u8bcd"},{"location":"jieba/#_1","text":"jieba \u201c\u7ed3\u5df4\u201d\u4e2d\u6587\u5206\u8bcd\uff1a\u505a\u6700\u597d\u7684 Python \u4e2d\u6587\u5206\u8bcd\u7ec4\u4ef6","title":"\u7ed3\u5df4\u5206\u8bcd"},{"location":"jieba/#_2","text":"\u652f\u6301\u4e09\u79cd\u5206\u8bcd\u6a21\u5f0f\uff1a \u7cbe\u786e\u6a21\u5f0f\uff0c\u8bd5\u56fe\u5c06\u53e5\u5b50\u6700\u7cbe\u786e\u5730\u5207\u5f00\uff0c\u9002\u5408\u6587\u672c\u5206\u6790\uff1b \u5168\u6a21\u5f0f\uff0c\u628a\u53e5\u5b50\u4e2d\u6240\u6709\u7684\u53ef\u4ee5\u6210\u8bcd\u7684\u8bcd\u8bed\u90fd\u626b\u63cf\u51fa\u6765, \u901f\u5ea6\u975e\u5e38\u5feb\uff0c\u4f46\u662f\u4e0d\u80fd\u89e3\u51b3\u6b67\u4e49\uff1b \u641c\u7d22\u5f15\u64ce\u6a21\u5f0f\uff0c\u5728\u7cbe\u786e\u6a21\u5f0f\u7684\u57fa\u7840\u4e0a\uff0c\u5bf9\u957f\u8bcd\u518d\u6b21\u5207\u5206\uff0c\u63d0\u9ad8\u53ec\u56de\u7387\uff0c\u9002\u5408\u7528\u4e8e\u641c\u7d22\u5f15\u64ce\u5206\u8bcd\u3002 \u652f\u6301\u7e41\u4f53\u5206\u8bcd \u652f\u6301\u81ea\u5b9a\u4e49\u8bcd\u5178 MIT \u6388\u6743\u534f\u8bae","title":"\u7279\u70b9"},{"location":"jieba/#_3","text":"\u57fa\u4e8e\u524d\u7f00\u8bcd\u5178\u5b9e\u73b0\u9ad8\u6548\u7684\u8bcd\u56fe\u626b\u63cf\uff0c\u751f\u6210\u53e5\u5b50\u4e2d\u6c49\u5b57\u6240\u6709\u53ef\u80fd\u6210\u8bcd\u60c5\u51b5\u6240\u6784\u6210\u7684 \u6709\u5411\u65e0\u73af\u56fe (DAG) \u91c7\u7528\u4e86\u52a8\u6001\u89c4\u5212\u67e5\u627e\u6700\u5927\u6982\u7387\u8def\u5f84, \u627e\u51fa\u57fa\u4e8e\u8bcd\u9891\u7684\u6700\u5927\u5207\u5206\u7ec4\u5408 \u5bf9\u4e8e\u672a\u767b\u5f55\u8bcd\uff0c\u91c7\u7528\u4e86\u57fa\u4e8e\u6c49\u5b57\u6210\u8bcd\u80fd\u529b\u7684 HMM \u6a21\u578b\uff0c\u4f7f\u7528\u4e86 Viterbi \u7b97\u6cd5","title":"\u7b97\u6cd5"},{"location":"nlpair-ictclas/","text":"NLPIR \u00b6 NLPIR \u6c49\u8bed\u5206\u8bcd\u7cfb\u7edf \u4e3b\u8981\u529f\u80fd\u5305\u62ec\u4e2d\u6587\u5206\u8bcd\uff1b\u82f1\u6587\u5206\u8bcd\uff1b\u8bcd\u6027\u6807\u6ce8\uff1b\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff1b\u65b0\u8bcd\u8bc6\u522b\uff1b\u5173\u952e\u8bcd\u63d0\u53d6\uff1b \u652f\u6301\u7528\u6237\u4e13\u4e1a\u8bcd\u5178\u4e0e\u5fae\u535a\u5206\u6790\u3002NLPIR \u7cfb\u7edf\u652f\u6301\u591a\u79cd\u7f16\u7801\u3001\u591a\u79cd\u64cd\u4f5c\u7cfb\u7edf\u3001\u591a\u79cd\u5f00\u53d1\u8bed\u8a00\u4e0e\u5e73\u53f0\u3002 \u529f\u80fd \u00b6 \u4e2d\u82f1\u6587\u6df7\u5408\u5206\u8bcd\u529f\u80fd \u00b6 \u81ea\u52a8\u5bf9\u4e2d\u6587\u82f1\u6587\u4fe1\u606f\u8fdb\u884c\u5206\u8bcd\u4e0e\u8bcd\u6027\u6807\u6ce8\u529f\u80fd\uff0c\u6db5\u76d6\u4e86\u4e2d\u6587\u5206\u8bcd\u3001\u82f1\u6587\u5206\u8bcd\u3001\u8bcd\u6027\u6807\u6ce8\u3001\u672a\u767b\u5f55\u8bcd\u8bc6\u522b\u4e0e\u7528\u6237\u8bcd\u5178\u7b49\u529f\u80fd\u3002 \u5173\u952e\u8bcd\u63d0\u53d6\u529f\u80fd \u00b6 \u91c7\u7528\u4ea4\u53c9\u4fe1\u606f\u71b5\u7684\u7b97\u6cd5\u81ea\u52a8\u8ba1\u7b97\u5173\u952e\u8bcd\uff0c\u5305\u62ec\u65b0\u8bcd\u4e0e\u5df2\u77e5\u8bcd\uff0c\u4e0b\u9762\u662f\u5bf9\u5341\u516b\u5c4a\u4e09\u4e2d\u5168\u4f1a\u62a5\u544a\u90e8\u5206\u5185\u5bb9\u7684\u5173\u952e\u8bcd\u63d0\u53d6\u7ed3\u679c\u3002 \u65b0\u8bcd\u8bc6\u522b\u4e0e\u81ea\u9002\u5e94\u5206\u8bcd\u529f\u80fd \u00b6 \u4ece\u8f83\u957f\u7684\u6587\u672c\u5185\u5bb9\u4e2d\uff0c\u57fa\u4e8e\u4fe1\u606f\u4ea4\u53c9\u71b5\u81ea\u52a8\u53d1\u73b0\u65b0\u7279\u5f81\u8bed\u8a00\uff0c\u5e76\u81ea\u9002\u5e94\u6d4b\u8bd5\u8bed\u6599\u7684\u8bed\u8a00\u6982\u7387\u5206\u5e03\u6a21\u578b\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u5206\u8bcd\u3002 \u7528\u6237\u4e13\u4e1a\u8bcd\u5178\u529f\u80fd \u00b6 \u53ef\u4ee5\u5355\u6761\u5bfc\u5165\u7528\u6237\u8bcd\u5178\uff0c\u4e5f\u53ef\u4ee5\u6279\u91cf\u5bfc\u5165\u7528\u6237\u8bcd\u5178\u3002\u5982\u53ef\u4ee5\u5b9a\u201c\u4e3e\u62a5\u4fe1 \u654f\u611f\u70b9\u201d\uff0c\u5176\u4e2d\u4e3e\u62a5\u4fe1\u662f\u7528\u6237\u8bcd\uff0c\u654f\u611f\u70b9\u662f\u7528\u6237\u81ea\u5b9a\u4e49\u7684\u8bcd\u6027\u6807\u8bb0\u3002","title":"NLPIR"},{"location":"nlpair-ictclas/#nlpir","text":"NLPIR \u6c49\u8bed\u5206\u8bcd\u7cfb\u7edf \u4e3b\u8981\u529f\u80fd\u5305\u62ec\u4e2d\u6587\u5206\u8bcd\uff1b\u82f1\u6587\u5206\u8bcd\uff1b\u8bcd\u6027\u6807\u6ce8\uff1b\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\uff1b\u65b0\u8bcd\u8bc6\u522b\uff1b\u5173\u952e\u8bcd\u63d0\u53d6\uff1b \u652f\u6301\u7528\u6237\u4e13\u4e1a\u8bcd\u5178\u4e0e\u5fae\u535a\u5206\u6790\u3002NLPIR \u7cfb\u7edf\u652f\u6301\u591a\u79cd\u7f16\u7801\u3001\u591a\u79cd\u64cd\u4f5c\u7cfb\u7edf\u3001\u591a\u79cd\u5f00\u53d1\u8bed\u8a00\u4e0e\u5e73\u53f0\u3002","title":"NLPIR"},{"location":"nlpair-ictclas/#_1","text":"","title":"\u529f\u80fd"},{"location":"nlpair-ictclas/#_2","text":"\u81ea\u52a8\u5bf9\u4e2d\u6587\u82f1\u6587\u4fe1\u606f\u8fdb\u884c\u5206\u8bcd\u4e0e\u8bcd\u6027\u6807\u6ce8\u529f\u80fd\uff0c\u6db5\u76d6\u4e86\u4e2d\u6587\u5206\u8bcd\u3001\u82f1\u6587\u5206\u8bcd\u3001\u8bcd\u6027\u6807\u6ce8\u3001\u672a\u767b\u5f55\u8bcd\u8bc6\u522b\u4e0e\u7528\u6237\u8bcd\u5178\u7b49\u529f\u80fd\u3002","title":"\u4e2d\u82f1\u6587\u6df7\u5408\u5206\u8bcd\u529f\u80fd"},{"location":"nlpair-ictclas/#_3","text":"\u91c7\u7528\u4ea4\u53c9\u4fe1\u606f\u71b5\u7684\u7b97\u6cd5\u81ea\u52a8\u8ba1\u7b97\u5173\u952e\u8bcd\uff0c\u5305\u62ec\u65b0\u8bcd\u4e0e\u5df2\u77e5\u8bcd\uff0c\u4e0b\u9762\u662f\u5bf9\u5341\u516b\u5c4a\u4e09\u4e2d\u5168\u4f1a\u62a5\u544a\u90e8\u5206\u5185\u5bb9\u7684\u5173\u952e\u8bcd\u63d0\u53d6\u7ed3\u679c\u3002","title":"\u5173\u952e\u8bcd\u63d0\u53d6\u529f\u80fd"},{"location":"nlpair-ictclas/#_4","text":"\u4ece\u8f83\u957f\u7684\u6587\u672c\u5185\u5bb9\u4e2d\uff0c\u57fa\u4e8e\u4fe1\u606f\u4ea4\u53c9\u71b5\u81ea\u52a8\u53d1\u73b0\u65b0\u7279\u5f81\u8bed\u8a00\uff0c\u5e76\u81ea\u9002\u5e94\u6d4b\u8bd5\u8bed\u6599\u7684\u8bed\u8a00\u6982\u7387\u5206\u5e03\u6a21\u578b\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u5206\u8bcd\u3002","title":"\u65b0\u8bcd\u8bc6\u522b\u4e0e\u81ea\u9002\u5e94\u5206\u8bcd\u529f\u80fd"},{"location":"nlpair-ictclas/#_5","text":"\u53ef\u4ee5\u5355\u6761\u5bfc\u5165\u7528\u6237\u8bcd\u5178\uff0c\u4e5f\u53ef\u4ee5\u6279\u91cf\u5bfc\u5165\u7528\u6237\u8bcd\u5178\u3002\u5982\u53ef\u4ee5\u5b9a\u201c\u4e3e\u62a5\u4fe1 \u654f\u611f\u70b9\u201d\uff0c\u5176\u4e2d\u4e3e\u62a5\u4fe1\u662f\u7528\u6237\u8bcd\uff0c\u654f\u611f\u70b9\u662f\u7528\u6237\u81ea\u5b9a\u4e49\u7684\u8bcd\u6027\u6807\u8bb0\u3002","title":"\u7528\u6237\u4e13\u4e1a\u8bcd\u5178\u529f\u80fd"},{"location":"awesome/","text":"awesome-nlp \u00b6 \u4e13\u95e8\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u7cbe\u9009\u8d44\u6e90\u5217\u8868 Maintainers - Keon , Martin , Nirant , Dhruv Please read the contribution guidelines before contributing. Please feel free to create pull requests . \u5185\u5bb9 \u00b6 Research Summaries and Trends Tutorials Reading Content Videos and Courses Books Libraries Node.js Python C++ Java Kotlin Scala R Clojure Ruby Rust Services Annotation Tools Datasets NLP in Korean NLP in Arabic NLP in Chinese NLP in German NLP in Spanish NLP in Indic Languages NLP in Thai NLP in Vietnamese NLP in Danish NLP in Indonesian Other Languages Credits \u7814\u7a76\u6458\u8981\u548c\u8d8b\u52bf \u00b6 NLP-\u6982\u89c2 \u662f\u5e94\u7528\u4e8e NLP \u7684\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u7684\u6700\u65b0\u6982\u8ff0\uff0c\u5305\u62ec\u7406\u8bba\uff0c\u5b9e\u73b0\uff0c\u5e94\u7528\u548c\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002 \u5bf9\u4e8e\u7814\u7a76\u4eba\u5458\u6765\u8bf4\uff0c\u8fd9\u662f\u4e00\u4e2a\u4f1f\u5927\u7684 Deep NLP \u7b80\u4ecb\u3002 NLP-\u8fdb\u5c55 \u8ddf\u8e2a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u8fdb\u5c55, \u5305\u62ec\u6570\u636e\u96c6\u548c\u6700\u5e38\u89c1\u7684 NLP \u4efb\u52a1\u7684\u5f53\u524d\u6700\u65b0\u6280\u672f NLP \u7684 ImageNet \u65f6\u523b\u5df2\u7ecf\u5230\u6765 ACL 2018 \u4eae\u70b9: \u5728\u66f4\u5177\u6311\u6218\u6027\u7684\u8bbe\u7f6e\u4e2d\u7406\u89e3\u8868\u793a\u548c\u8bc4\u4f30 ACL 2017 \u7684\u56db\u4e2a\u6df1\u5ea6\u5b66\u4e60\u8d8b\u52bf\u3002\u7b2c\u4e00\u90e8\u5206: \u8bed\u8a00\u7ed3\u6784\u548c\u8bcd\u5d4c\u5165 ACL 2017 \u7684\u56db\u4e2a\u6df1\u5ea6\u5b66\u4e60\u8d8b\u52bf\u3002\u7b2c\u4e8c\u90e8\u5206: \u53ef\u89e3\u91ca\u6027\u548c\u6ce8\u610f\u529b EMNLP 2017 \u7684\u4eae\u70b9: \u4ee4\u4eba\u5174\u594b\u7684\u6570\u636e\u96c6\uff0c\u7fa4\u96c6\u7684\u8fd4\u56de\u7b49\u7b49\uff01 \u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u6df1\u5ea6\u5b66\u4e60 (NLP): \u8fdb\u6b65\u4e0e\u8d8b\u52bf \u81ea\u7136\u8bed\u8a00\u751f\u6210\u7684\u73b0\u72b6\u8c03\u67e5 \u521d\u59cb\u7b56\u5c55\u4eba\u548c\u6765\u6e90\u7684 \u79ef\u5206","title":"awesome-nlp"},{"location":"awesome/#awesome-nlp","text":"\u4e13\u95e8\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u7cbe\u9009\u8d44\u6e90\u5217\u8868 Maintainers - Keon , Martin , Nirant , Dhruv Please read the contribution guidelines before contributing. Please feel free to create pull requests .","title":"awesome-nlp"},{"location":"awesome/#_1","text":"Research Summaries and Trends Tutorials Reading Content Videos and Courses Books Libraries Node.js Python C++ Java Kotlin Scala R Clojure Ruby Rust Services Annotation Tools Datasets NLP in Korean NLP in Arabic NLP in Chinese NLP in German NLP in Spanish NLP in Indic Languages NLP in Thai NLP in Vietnamese NLP in Danish NLP in Indonesian Other Languages Credits","title":"\u5185\u5bb9"},{"location":"awesome/#_2","text":"NLP-\u6982\u89c2 \u662f\u5e94\u7528\u4e8e NLP \u7684\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u7684\u6700\u65b0\u6982\u8ff0\uff0c\u5305\u62ec\u7406\u8bba\uff0c\u5b9e\u73b0\uff0c\u5e94\u7528\u548c\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002 \u5bf9\u4e8e\u7814\u7a76\u4eba\u5458\u6765\u8bf4\uff0c\u8fd9\u662f\u4e00\u4e2a\u4f1f\u5927\u7684 Deep NLP \u7b80\u4ecb\u3002 NLP-\u8fdb\u5c55 \u8ddf\u8e2a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u8fdb\u5c55, \u5305\u62ec\u6570\u636e\u96c6\u548c\u6700\u5e38\u89c1\u7684 NLP \u4efb\u52a1\u7684\u5f53\u524d\u6700\u65b0\u6280\u672f NLP \u7684 ImageNet \u65f6\u523b\u5df2\u7ecf\u5230\u6765 ACL 2018 \u4eae\u70b9: \u5728\u66f4\u5177\u6311\u6218\u6027\u7684\u8bbe\u7f6e\u4e2d\u7406\u89e3\u8868\u793a\u548c\u8bc4\u4f30 ACL 2017 \u7684\u56db\u4e2a\u6df1\u5ea6\u5b66\u4e60\u8d8b\u52bf\u3002\u7b2c\u4e00\u90e8\u5206: \u8bed\u8a00\u7ed3\u6784\u548c\u8bcd\u5d4c\u5165 ACL 2017 \u7684\u56db\u4e2a\u6df1\u5ea6\u5b66\u4e60\u8d8b\u52bf\u3002\u7b2c\u4e8c\u90e8\u5206: \u53ef\u89e3\u91ca\u6027\u548c\u6ce8\u610f\u529b EMNLP 2017 \u7684\u4eae\u70b9: \u4ee4\u4eba\u5174\u594b\u7684\u6570\u636e\u96c6\uff0c\u7fa4\u96c6\u7684\u8fd4\u56de\u7b49\u7b49\uff01 \u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u6df1\u5ea6\u5b66\u4e60 (NLP): \u8fdb\u6b65\u4e0e\u8d8b\u52bf \u81ea\u7136\u8bed\u8a00\u751f\u6210\u7684\u73b0\u72b6\u8c03\u67e5 \u521d\u59cb\u7b56\u5c55\u4eba\u548c\u6765\u6e90\u7684 \u79ef\u5206","title":"\u7814\u7a76\u6458\u8981\u548c\u8d8b\u52bf"},{"location":"awesome/datasets/","text":"\u6570\u636e\u96c6 nlp-datasets \u00b6 nlp-datasets great collection of nlp datasets Alphabetical list of free/public domain datasets with text data for use in Natural Language Processing (NLP). Most stuff here is just raw unstructured text data, if you are looking for annotated corpora or Treebanks refer to the sources at the bottom. Datasets (English, multilang) \u00b6 Apache Software Foundation Public Mail Archives : all publicly available Apache Software Foundation mail archives as of July 11, 2011 (200 GB) Blog Authorship Corpus : consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. 681,288 posts and over 140 million words. (298 MB) Amazon Fine Food Reviews [Kaggle] : consists of 568,454 food reviews Amazon users left up to October 2012. Paper . (240 MB) Amazon Reviews : Stanford collection of 35 million amazon reviews. (11 GB) ArXiv : All the Papers on archive as fulltext (270 GB) + sourcefiles (190 GB). ASAP Automated Essay Scoring [Kaggle] : For this competition, there are eight essay sets. Each of the sets of essays was generated from a single prompt. Selected essays range from an average length of 150 to 550 words per response. Some of the essays are dependent upon source information and others are not. All responses were written by students ranging in grade levels from Grade 7 to Grade 10. All essays were hand graded and were double-scored. (100 MB) ASAP Short Answer Scoring [Kaggle] : Each of the data sets was generated from a single prompt. Selected responses have an average length of 50 words per response. Some of the essays are dependent upon source information and others are not. All responses were written by students primarily in Grade 10. All responses were hand graded and were double-scored. (35 MB) Classification of political social media : Social media messages from politicians classified by content. (4 MB) CLiPS Stylometry Investigation (CSI) Corpus : a yearly expanded corpus of student texts in two genres: essays and reviews. The purpose of this corpus lies primarily in stylometric research, but other applications are possible. (on request) ClueWeb09 FACC : ClueWeb09 with Freebase annotations (72 GB) ClueWeb11 FACC : ClueWeb11 with Freebase annotations (92 GB) Common Crawl Corpus : web crawl data composed of over 5 billion web pages (541 TB) Cornell Movie Dialog Corpus : contains a large metadata-rich collection of fictional conversations extracted from raw movie scripts: 220,579 conversational exchanges between 10,292 pairs of movie characters, 617 movies (9.5 MB) Corporate messaging : A data categorization job concerning what corporations actually talk about on social media. Contributors were asked to classify statements as information (objective statements about the company or it\u2019s activities), dialog (replies to users, etc.), or action (messages that ask for votes or ask users to click on links, etc.). (600 KB) Crosswikis : English-phrase-to-associated-Wikipedia-article database. Paper. (11 GB) DBpedia : a community effort to extract structured information from Wikipedia and to make this information available on the Web (17 GB) Death Row : last words of every inmate executed since 1984 online (HTML table) Del.icio.us : 1.25 million bookmarks on delicious.com (170 MB) Disasters on social media : 10,000 tweets with annotations whether the tweet referred to a disaster event (2 MB). Economic News Article Tone and Relevance : News articles judged if relevant to the US economy and, if so, what the tone of the article was. Dates range from 1951 to 2014. (12 MB) Enron Email Data : consists of 1,227,255 emails with 493,384 attachments covering 151 custodians (210 GB) Event Registry : Free tool that gives real time access to news articles by 100.000 news publishers worldwide. Has API . (query tool) Examiner.com - Spam Clickbait News Headlines [Kaggle] : 3 Million crowdsourced News headlines published by now defunct clickbait website The Examiner from 2010 to 2015. (200 MB) Federal Contracts from the Federal Procurement Data Center (USASpending.gov) : data dump of all federal contracts from the Federal Procurement Data Center found at USASpending.gov (180 GB) Flickr Personal Taxonomies : Tree dataset of personal tags (40 MB) Freebase Data Dump : data dump of all the current facts and assertions in Freebase (26 GB) Freebase Simple Topic Dump : data dump of the basic identifying facts about every topic in Freebase (5 GB) Freebase Quad Dump : data dump of all the current facts and assertions in Freebase (35 GB) GigaOM Wordpress Challenge [Kaggle] : blog posts, meta data, user likes (1.5 GB) Google Books Ngrams : available also in hadoop format on amazon s3 (2.2 TB) Google Web 5gram : contains English word n-grams and their observed frequency counts (24 GB) Gutenberg Ebook List : annotated list of ebooks (2 MB) Hansards text chunks of Canadian Parliament : 1.3 million pairs of aligned text chunks (sentences or smaller fragments) from the official records (Hansards) of the 36th Canadian Parliament. (82 MB) Harvard Library : over 12 million bibliographic records for materials held by the Harvard Library, including books, journals, electronic resources, manuscripts, archival materials, scores, audio, video and other materials. (4 GB) Hate speech identification : Contributors viewed short text and identified if it a) contained hate speech, b) was offensive but without hate speech, or c) was not offensive at all. Contains nearly 15K rows with three contributor judgments per text string. (3 MB) Hillary Clinton Emails [Kaggle] : nearly 7,000 pages of Clinton's heavily redacted emails (12 MB) Historical Newspapers Yearly N-grams and Entities Dataset : Yearly time series for the usage of the 1,000,000 most frequent 1-, 2-, and 3-grams from a subset of the British Newspaper Archive corpus, along with yearly time series for the 100,000 most frequent named entities linked to Wikipedia and a list of all articles and newspapers contained in the dataset (3.1 GB) Historical Newspapers Daily Word Time Series Dataset : Time series of daily word usage for the 25,000 most frequent words in 87 years of UK and US historical newspapers between 1836 and 1922. (2.7GB) Home Depot Product Search Relevance [Kaggle] : contains a number of products and real customer search terms from Home Depot's website. The challenge is to predict a relevance score for the provided combinations of search terms and products. To create the ground truth labels, Home Depot has crowdsourced the search/product pairs to multiple human raters. (65 MB) Identifying key phrases in text : Question/Answer pairs + context; context was judged if relevant to question/answer. (8 MB) Jeopardy : archive of 216,930 past Jeopardy questions (53 MB) 200k English plaintext jokes : archive of 208,000 plaintext jokes from various sources. Machine Translation of European Languages : (612 MB) Material Safety Datasheets : 230,000 Material Safety Data Sheets. (3 GB) Million News Headlines - ABC Australia [Kaggle] : 1.3 Million News headlines published by ABC News Australia from 2003 to 2017. (56 MB) Millions of News Article URLs : 2.3 million URLs for news articles from the frontpage of over 950 English-language news outlets in the six month period between October 2014 and April 2015. (101MB) MCTest : a freely available set of 660 stories and associated questions intended for research on the machine comprehension of text; for question answering (1 MB) News Headlines of India - Times of India [Kaggle] : 2.7 Million News Headlines with category published by Times of India from 2001 to 2017. (185 MB) News article / Wikipedia page pairings : Contributors read a short article and were asked which of two Wikipedia articles it matched most closely. (6 MB) NIPS2015 Papers (version 2) [Kaggle] : full text of all NIPS2015 papers (335 MB) NYTimes Facebook Data : all the NYTimes facebook posts (5 MB) One Week of Global News Feeds [Kaggle] : News Event Dataset of 1.4 Million Articles published globally in 20 languages over one week of August 2017. (115 MB) Objective truths of sentences/concept pairs : Contributors read a sentence with two concepts. For example \u201ca dog is a kind of animal\u201d or \u201ccaptain can have the same meaning as master.\u201d They were then asked if the sentence could be true and ranked it on a 1-5 scale. (700 KB) Open Library Data Dumps : dump of all revisions of all the records in Open Library. (16 GB) Personae Corpus : collected for experiments in Authorship Attribution and Personality Prediction. It consists of 145 Dutch-language essays by 145 different students. (on request) Reddit Comments : every publicly available reddit comment as of july 2015. 1.7 billion comments (250 GB) Reddit Comments (May \u201815) [Kaggle] : subset of above dataset (8 GB) Reddit Submission Corpus : all publicly available Reddit submissions from January 2006 - August 31, 2015). (42 GB) Reuters Corpus : a large collection of Reuters News stories for use in research and development of natural language processing, information retrieval, and machine learning systems. This corpus, known as \"Reuters Corpus, Volume 1\" or RCV1, is significantly larger than the older, well-known Reuters-21578 collection heavily used in the text classification community. Need to sign agreement and sent per post to obtain. (2.5 GB) SMS Spam Collection : 5,574 English, real and non-enconded SMS messages, tagged according being legitimate (ham) or spam. (200 KB) SouthparkData : .csv files containing script information including: season, episode, character, & line. (3.6 MB) Stanford Question Answering Dataset (SQUAD 2.0) : a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable. Stackoverflow : 7.3 million stackoverflow questions + other stackexchanges (query tool) Twitter Cheng-Caverlee-Lee Scrape : Tweets from September 2009 - January 2010, geolocated. (400 MB) Twitter New England Patriots Deflategate sentiment : Before the 2015 Super Bowl, there was a great deal of chatter around deflated footballs and whether the Patriots cheated. This data set looks at Twitter sentiment on important days during the scandal to gauge public sentiment about the whole ordeal. (2 MB) Twitter Progressive issues sentiment analysis : tweets regarding a variety of left-leaning issues like legalization of abortion, feminism, Hillary Clinton, etc. classified if the tweets in question were for, against, or neutral on the issue (with an option for none of the above). (600 KB) Twitter Sentiment140 : Tweets related to brands/keywords. Website includes papers and research ideas. (77 MB) Twitter sentiment analysis: Self-driving cars : contributors read tweets and classified them as very positive, slightly positive, neutral, slightly negative, or very negative. They were also prompted asked to mark if the tweet was not relevant to self-driving cars. (1 MB) Twitter Elections Integrity : All suspicious tweets and media from 2016 US election. (1.4 GB) Twitter Tokyo Geolocated Tweets : 200K tweets from Tokyo. (47 MB) Twitter UK Geolocated Tweets : 170K tweets from UK. (47 MB) Twitter USA Geolocated Tweets : 200k tweets from the US (45MB) Twitter US Airline Sentiment [Kaggle] : A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\"). (2.5 MB) U.S. economic performance based on news articles : News articles headlines and excerpts ranked as whether relevant to U.S. economy. (5 MB) Urban Dictionary Words and Definitions [Kaggle] : Cleaned CSV corpus of 2.6 Million of all Urban Dictionary words, definitions, authors, votes as of May 2016. (238 MB) Wesbury Lab Usenet Corpus : anonymized compilation of postings from 47,860 English-language newsgroups from 2005-2010 (40 GB) Wesbury Lab Wikipedia Corpus Snapshot of all the articles in the English part of the Wikipedia that was taken in April 2010. It was processed, as described in detail below, to remove all links and irrelevant material (navigation text, etc) The corpus is untagged, raw text. Used by Stanford NLP (1.8 GB). WorldTree Corpus of Explanation Graphs for Elementary Science Questions : a corpus of manually-constructed explanation graphs, explanatory role ratings, and associated semistructured tablestore for most publicly available elementary science exam questions in the US (8 MB) Wikipedia Extraction (WEX) : a processed dump of english language wikipedia (66 GB) Wikipedia XML Data : complete copy of all Wikimedia wikis, in the form of wikitext source and metadata embedded in XML. (500 GB) Yahoo! Answers Comprehensive Questions and Answers : Yahoo! Answers corpus as of 10/25/2007. Contains 4,483,032 questions and their answers. (3.6 GB) Yahoo! Answers consisting of questions asked in French : Subset of the Yahoo! Answers corpus from 2006 to 2015 consisting of 1.7 million questions posed in French, and their corresponding answers. (3.8 GB) Yahoo! Answers Manner Questions : subset of the Yahoo! Answers corpus from a 10/25/2007 dump, selected for their linguistic properties. Contains 142,627 questions and their answers. (104 MB) Yahoo! HTML Forms Extracted from Publicly Available Webpages : contains a small sample of pages that contain complex HTML forms, contains 2.67 million complex forms. (50+ GB) Yahoo! Metadata Extracted from Publicly Available Web Pages : 100 million triples of RDF data (2 GB) Yahoo N-Gram Representations : This dataset contains n-gram representations. The data may serve as a testbed for query rewriting task, a common problem in IR research as well as to word and sentence similarity task, which is common in NLP research. (2.6 GB) Yahoo! N-Grams, version 2.0 : n-grams (n = 1 to 5), extracted from a corpus of 14.6 million documents (126 million unique sentences, 3.4 billion running words) crawled from over 12000 news-oriented sites (12 GB) Yahoo! Search Logs with Relevance Judgments : Annonymized Yahoo! Search Logs with Relevance Judgments (1.3 GB) Yahoo! Semantically Annotated Snapshot of the English Wikipedia : English Wikipedia dated from 2006-11-04 processed with a number of publicly-available NLP tools. 1,490,688 entries. (6 GB) Yelp : including restaurant rankings and 2.2M reviews (on request) Youtube : 1.7 million youtube videos descriptions (torrent) Sources \u00b6 Awesome public datasets/NLP (includes more lists) AWS Public Datasets CrowdFlower: Data for Everyone (lots of little surveys they conducted and data obtained by crowdsourcing for a specific task) Kaggle 1 , 2 (make sure though that the kaggle competition data can be used outside of the competition!) Open Library Quora (mainly annotated corpora) /r/datasets (endless list of datasets, most is scraped by amateurs though and not properly documented or licensed) rs.io (another big list) Stackexchange: Opendata Stanford NLP group (mainly annotated corpora and TreeBanks or actual NLP tools) Yahoo! Webscope (also includes papers that use the data that is provided) Datasets (Arabic) \u00b6 SaudiNewsNet : 31,030 Arabic newspaper articles alongwith metadata, extracted from various online Saudi newspapers. (2 MB) Datasets (German) \u00b6 German Political Speeches Corpus : collection of recent speeches held by top German representatives (25 MB, 11 MTokens) NEGRA : A Syntactically Annotated Corpus of German Newspaper Texts. Available for free for all Universities and non-profit organizations. Need to sign and send form to obtain. (on request) Ten Thousand German News Articles Dataset : 10273 german language news articles categorized into nine classes for topic classification. (26.1 MB)","title":"\u6570\u636e\u96c6 nlp-datasets"},{"location":"awesome/datasets/#nlp-datasets","text":"nlp-datasets great collection of nlp datasets Alphabetical list of free/public domain datasets with text data for use in Natural Language Processing (NLP). Most stuff here is just raw unstructured text data, if you are looking for annotated corpora or Treebanks refer to the sources at the bottom.","title":"\u6570\u636e\u96c6 nlp-datasets"},{"location":"awesome/datasets/#datasets-english-multilang","text":"Apache Software Foundation Public Mail Archives : all publicly available Apache Software Foundation mail archives as of July 11, 2011 (200 GB) Blog Authorship Corpus : consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. 681,288 posts and over 140 million words. (298 MB) Amazon Fine Food Reviews [Kaggle] : consists of 568,454 food reviews Amazon users left up to October 2012. Paper . (240 MB) Amazon Reviews : Stanford collection of 35 million amazon reviews. (11 GB) ArXiv : All the Papers on archive as fulltext (270 GB) + sourcefiles (190 GB). ASAP Automated Essay Scoring [Kaggle] : For this competition, there are eight essay sets. Each of the sets of essays was generated from a single prompt. Selected essays range from an average length of 150 to 550 words per response. Some of the essays are dependent upon source information and others are not. All responses were written by students ranging in grade levels from Grade 7 to Grade 10. All essays were hand graded and were double-scored. (100 MB) ASAP Short Answer Scoring [Kaggle] : Each of the data sets was generated from a single prompt. Selected responses have an average length of 50 words per response. Some of the essays are dependent upon source information and others are not. All responses were written by students primarily in Grade 10. All responses were hand graded and were double-scored. (35 MB) Classification of political social media : Social media messages from politicians classified by content. (4 MB) CLiPS Stylometry Investigation (CSI) Corpus : a yearly expanded corpus of student texts in two genres: essays and reviews. The purpose of this corpus lies primarily in stylometric research, but other applications are possible. (on request) ClueWeb09 FACC : ClueWeb09 with Freebase annotations (72 GB) ClueWeb11 FACC : ClueWeb11 with Freebase annotations (92 GB) Common Crawl Corpus : web crawl data composed of over 5 billion web pages (541 TB) Cornell Movie Dialog Corpus : contains a large metadata-rich collection of fictional conversations extracted from raw movie scripts: 220,579 conversational exchanges between 10,292 pairs of movie characters, 617 movies (9.5 MB) Corporate messaging : A data categorization job concerning what corporations actually talk about on social media. Contributors were asked to classify statements as information (objective statements about the company or it\u2019s activities), dialog (replies to users, etc.), or action (messages that ask for votes or ask users to click on links, etc.). (600 KB) Crosswikis : English-phrase-to-associated-Wikipedia-article database. Paper. (11 GB) DBpedia : a community effort to extract structured information from Wikipedia and to make this information available on the Web (17 GB) Death Row : last words of every inmate executed since 1984 online (HTML table) Del.icio.us : 1.25 million bookmarks on delicious.com (170 MB) Disasters on social media : 10,000 tweets with annotations whether the tweet referred to a disaster event (2 MB). Economic News Article Tone and Relevance : News articles judged if relevant to the US economy and, if so, what the tone of the article was. Dates range from 1951 to 2014. (12 MB) Enron Email Data : consists of 1,227,255 emails with 493,384 attachments covering 151 custodians (210 GB) Event Registry : Free tool that gives real time access to news articles by 100.000 news publishers worldwide. Has API . (query tool) Examiner.com - Spam Clickbait News Headlines [Kaggle] : 3 Million crowdsourced News headlines published by now defunct clickbait website The Examiner from 2010 to 2015. (200 MB) Federal Contracts from the Federal Procurement Data Center (USASpending.gov) : data dump of all federal contracts from the Federal Procurement Data Center found at USASpending.gov (180 GB) Flickr Personal Taxonomies : Tree dataset of personal tags (40 MB) Freebase Data Dump : data dump of all the current facts and assertions in Freebase (26 GB) Freebase Simple Topic Dump : data dump of the basic identifying facts about every topic in Freebase (5 GB) Freebase Quad Dump : data dump of all the current facts and assertions in Freebase (35 GB) GigaOM Wordpress Challenge [Kaggle] : blog posts, meta data, user likes (1.5 GB) Google Books Ngrams : available also in hadoop format on amazon s3 (2.2 TB) Google Web 5gram : contains English word n-grams and their observed frequency counts (24 GB) Gutenberg Ebook List : annotated list of ebooks (2 MB) Hansards text chunks of Canadian Parliament : 1.3 million pairs of aligned text chunks (sentences or smaller fragments) from the official records (Hansards) of the 36th Canadian Parliament. (82 MB) Harvard Library : over 12 million bibliographic records for materials held by the Harvard Library, including books, journals, electronic resources, manuscripts, archival materials, scores, audio, video and other materials. (4 GB) Hate speech identification : Contributors viewed short text and identified if it a) contained hate speech, b) was offensive but without hate speech, or c) was not offensive at all. Contains nearly 15K rows with three contributor judgments per text string. (3 MB) Hillary Clinton Emails [Kaggle] : nearly 7,000 pages of Clinton's heavily redacted emails (12 MB) Historical Newspapers Yearly N-grams and Entities Dataset : Yearly time series for the usage of the 1,000,000 most frequent 1-, 2-, and 3-grams from a subset of the British Newspaper Archive corpus, along with yearly time series for the 100,000 most frequent named entities linked to Wikipedia and a list of all articles and newspapers contained in the dataset (3.1 GB) Historical Newspapers Daily Word Time Series Dataset : Time series of daily word usage for the 25,000 most frequent words in 87 years of UK and US historical newspapers between 1836 and 1922. (2.7GB) Home Depot Product Search Relevance [Kaggle] : contains a number of products and real customer search terms from Home Depot's website. The challenge is to predict a relevance score for the provided combinations of search terms and products. To create the ground truth labels, Home Depot has crowdsourced the search/product pairs to multiple human raters. (65 MB) Identifying key phrases in text : Question/Answer pairs + context; context was judged if relevant to question/answer. (8 MB) Jeopardy : archive of 216,930 past Jeopardy questions (53 MB) 200k English plaintext jokes : archive of 208,000 plaintext jokes from various sources. Machine Translation of European Languages : (612 MB) Material Safety Datasheets : 230,000 Material Safety Data Sheets. (3 GB) Million News Headlines - ABC Australia [Kaggle] : 1.3 Million News headlines published by ABC News Australia from 2003 to 2017. (56 MB) Millions of News Article URLs : 2.3 million URLs for news articles from the frontpage of over 950 English-language news outlets in the six month period between October 2014 and April 2015. (101MB) MCTest : a freely available set of 660 stories and associated questions intended for research on the machine comprehension of text; for question answering (1 MB) News Headlines of India - Times of India [Kaggle] : 2.7 Million News Headlines with category published by Times of India from 2001 to 2017. (185 MB) News article / Wikipedia page pairings : Contributors read a short article and were asked which of two Wikipedia articles it matched most closely. (6 MB) NIPS2015 Papers (version 2) [Kaggle] : full text of all NIPS2015 papers (335 MB) NYTimes Facebook Data : all the NYTimes facebook posts (5 MB) One Week of Global News Feeds [Kaggle] : News Event Dataset of 1.4 Million Articles published globally in 20 languages over one week of August 2017. (115 MB) Objective truths of sentences/concept pairs : Contributors read a sentence with two concepts. For example \u201ca dog is a kind of animal\u201d or \u201ccaptain can have the same meaning as master.\u201d They were then asked if the sentence could be true and ranked it on a 1-5 scale. (700 KB) Open Library Data Dumps : dump of all revisions of all the records in Open Library. (16 GB) Personae Corpus : collected for experiments in Authorship Attribution and Personality Prediction. It consists of 145 Dutch-language essays by 145 different students. (on request) Reddit Comments : every publicly available reddit comment as of july 2015. 1.7 billion comments (250 GB) Reddit Comments (May \u201815) [Kaggle] : subset of above dataset (8 GB) Reddit Submission Corpus : all publicly available Reddit submissions from January 2006 - August 31, 2015). (42 GB) Reuters Corpus : a large collection of Reuters News stories for use in research and development of natural language processing, information retrieval, and machine learning systems. This corpus, known as \"Reuters Corpus, Volume 1\" or RCV1, is significantly larger than the older, well-known Reuters-21578 collection heavily used in the text classification community. Need to sign agreement and sent per post to obtain. (2.5 GB) SMS Spam Collection : 5,574 English, real and non-enconded SMS messages, tagged according being legitimate (ham) or spam. (200 KB) SouthparkData : .csv files containing script information including: season, episode, character, & line. (3.6 MB) Stanford Question Answering Dataset (SQUAD 2.0) : a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable. Stackoverflow : 7.3 million stackoverflow questions + other stackexchanges (query tool) Twitter Cheng-Caverlee-Lee Scrape : Tweets from September 2009 - January 2010, geolocated. (400 MB) Twitter New England Patriots Deflategate sentiment : Before the 2015 Super Bowl, there was a great deal of chatter around deflated footballs and whether the Patriots cheated. This data set looks at Twitter sentiment on important days during the scandal to gauge public sentiment about the whole ordeal. (2 MB) Twitter Progressive issues sentiment analysis : tweets regarding a variety of left-leaning issues like legalization of abortion, feminism, Hillary Clinton, etc. classified if the tweets in question were for, against, or neutral on the issue (with an option for none of the above). (600 KB) Twitter Sentiment140 : Tweets related to brands/keywords. Website includes papers and research ideas. (77 MB) Twitter sentiment analysis: Self-driving cars : contributors read tweets and classified them as very positive, slightly positive, neutral, slightly negative, or very negative. They were also prompted asked to mark if the tweet was not relevant to self-driving cars. (1 MB) Twitter Elections Integrity : All suspicious tweets and media from 2016 US election. (1.4 GB) Twitter Tokyo Geolocated Tweets : 200K tweets from Tokyo. (47 MB) Twitter UK Geolocated Tweets : 170K tweets from UK. (47 MB) Twitter USA Geolocated Tweets : 200k tweets from the US (45MB) Twitter US Airline Sentiment [Kaggle] : A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\"). (2.5 MB) U.S. economic performance based on news articles : News articles headlines and excerpts ranked as whether relevant to U.S. economy. (5 MB) Urban Dictionary Words and Definitions [Kaggle] : Cleaned CSV corpus of 2.6 Million of all Urban Dictionary words, definitions, authors, votes as of May 2016. (238 MB) Wesbury Lab Usenet Corpus : anonymized compilation of postings from 47,860 English-language newsgroups from 2005-2010 (40 GB) Wesbury Lab Wikipedia Corpus Snapshot of all the articles in the English part of the Wikipedia that was taken in April 2010. It was processed, as described in detail below, to remove all links and irrelevant material (navigation text, etc) The corpus is untagged, raw text. Used by Stanford NLP (1.8 GB). WorldTree Corpus of Explanation Graphs for Elementary Science Questions : a corpus of manually-constructed explanation graphs, explanatory role ratings, and associated semistructured tablestore for most publicly available elementary science exam questions in the US (8 MB) Wikipedia Extraction (WEX) : a processed dump of english language wikipedia (66 GB) Wikipedia XML Data : complete copy of all Wikimedia wikis, in the form of wikitext source and metadata embedded in XML. (500 GB) Yahoo! Answers Comprehensive Questions and Answers : Yahoo! Answers corpus as of 10/25/2007. Contains 4,483,032 questions and their answers. (3.6 GB) Yahoo! Answers consisting of questions asked in French : Subset of the Yahoo! Answers corpus from 2006 to 2015 consisting of 1.7 million questions posed in French, and their corresponding answers. (3.8 GB) Yahoo! Answers Manner Questions : subset of the Yahoo! Answers corpus from a 10/25/2007 dump, selected for their linguistic properties. Contains 142,627 questions and their answers. (104 MB) Yahoo! HTML Forms Extracted from Publicly Available Webpages : contains a small sample of pages that contain complex HTML forms, contains 2.67 million complex forms. (50+ GB) Yahoo! Metadata Extracted from Publicly Available Web Pages : 100 million triples of RDF data (2 GB) Yahoo N-Gram Representations : This dataset contains n-gram representations. The data may serve as a testbed for query rewriting task, a common problem in IR research as well as to word and sentence similarity task, which is common in NLP research. (2.6 GB) Yahoo! N-Grams, version 2.0 : n-grams (n = 1 to 5), extracted from a corpus of 14.6 million documents (126 million unique sentences, 3.4 billion running words) crawled from over 12000 news-oriented sites (12 GB) Yahoo! Search Logs with Relevance Judgments : Annonymized Yahoo! Search Logs with Relevance Judgments (1.3 GB) Yahoo! Semantically Annotated Snapshot of the English Wikipedia : English Wikipedia dated from 2006-11-04 processed with a number of publicly-available NLP tools. 1,490,688 entries. (6 GB) Yelp : including restaurant rankings and 2.2M reviews (on request) Youtube : 1.7 million youtube videos descriptions (torrent)","title":"Datasets (English, multilang)"},{"location":"awesome/datasets/#sources","text":"Awesome public datasets/NLP (includes more lists) AWS Public Datasets CrowdFlower: Data for Everyone (lots of little surveys they conducted and data obtained by crowdsourcing for a specific task) Kaggle 1 , 2 (make sure though that the kaggle competition data can be used outside of the competition!) Open Library Quora (mainly annotated corpora) /r/datasets (endless list of datasets, most is scraped by amateurs though and not properly documented or licensed) rs.io (another big list) Stackexchange: Opendata Stanford NLP group (mainly annotated corpora and TreeBanks or actual NLP tools) Yahoo! Webscope (also includes papers that use the data that is provided)","title":"Sources"},{"location":"awesome/datasets/#datasets-arabic","text":"SaudiNewsNet : 31,030 Arabic newspaper articles alongwith metadata, extracted from various online Saudi newspapers. (2 MB)","title":"Datasets (Arabic)"},{"location":"awesome/datasets/#datasets-german","text":"German Political Speeches Corpus : collection of recent speeches held by top German representatives (25 MB, 11 MTokens) NEGRA : A Syntactically Annotated Corpus of German Newspaper Texts. Available for free for all Universities and non-profit organizations. Need to sign and send form to obtain. (on request) Ten Thousand German News Articles Dataset : 10273 german language news articles categorized into nine classes for topic classification. (26.1 MB)","title":"Datasets (German)"},{"location":"awesome/libraries/","text":"\u5e93 \u00b6 \u8bed\u8a00\u5e93 \u00b6 Node.js \u548c Javascript \u00b6 Node.js NLP \u7684\u5e93 Twitter-text - Twitter \u7684\u6587\u672c\u5904\u7406\u5e93\u7684 JavaScript \u5b9e\u73b0 Knwl.js - JS \u4e2d\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5668 Retext - \u7528\u4e8e\u5206\u6790\u548c\u64cd\u7eb5\u81ea\u7136\u8bed\u8a00\u7684\u53ef\u6269\u5c55\u7cfb\u7edf NLP Compromise - \u6d4f\u89c8\u5668\u4e2d\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406 Natural - \u8282\u70b9\u7684\u4e00\u822c\u81ea\u7136\u8bed\u8a00\u8bbe\u65bd Poplar - \u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u7684\u57fa\u4e8e Web \u7684\u6ce8\u91ca\u5de5\u5177 Python \u00b6 Python NLP \u5e93 TextBlob - Providing a consistent API for diving into common natural language processing (NLP) tasks. Stands on the giant shoulders of Natural Language Toolkit (NLTK) and Pattern , and plays nicely with both :+1: spaCy - Industrial strength NLP with Python and Cython :+1: textacy - Higher level NLP built on spaCy gensim - Python library to conduct unsupervised semantic modelling from plain text :+1: scattertext - Python library to produce d3 visualizations of how language differs between corpora AllenNLP - An NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks. PyTorch-NLP - NLP research toolkit designed to support rapid prototyping with better data loaders, word vector loaders, neural network layer representations, common NLP metrics such as BLEU Rosetta - Text processing tools and wrappers (e.g. Vowpal Wabbit) PyNLPl - Python Natural Language Processing Library. General purpose NLP library for Python. Also contains some specific modules for parsing common NLP formats, most notably for FoLiA , but also ARPA language models, Moses phrasetables, GIZA++ alignments. jPTDP - A toolkit for joint part-of-speech (POS) tagging and dependency parsing. jPTDP provides pre-trained models for 40+ languages. BigARTM - a fast library for topic modelling Snips NLU - A production ready library for intent parsing Chazutsu - A library for downloading&parsing standard NLP research datasets Word Forms - Word forms can accurately generate all possible forms of an English word Multilingual Latent Dirichlet Allocation (LDA) - A multilingual and extensible document clustering pipeline NLP Architect - A library for exploring the state-of-the-art deep learning topologies and techniques for NLP and NLU Flair - A very simple framework for state-of-the-art multilingual NLP built on PyTorch. Includes BERT, ELMo and Flair embeddings. Kashgari - Simple, Keras-powered multilingual NLP framework, allows you to build your models in 5 minutes for named entity recognition (NER), part-of-speech tagging (PoS) and text classification tasks. Includes BERT and word2vec embedding. C++ \u00b6 C++ \u5e93 MIT Information Extraction Toolkit - C, C++, and Python tools for named entity recognition and relation extraction CRF++ - Open source implementation of Conditional Random Fields (CRFs) for segmenting/labeling sequential data & other Natural Language Processing tasks. CRFsuite - CRFsuite is an implementation of Conditional Random Fields (CRFs) for labeling sequential data. BLLIP Parser - BLLIP Natural Language Parser (also known as the Charniak-Johnson parser) colibri-core - C++ library, command line tools, and Python binding for extracting and working with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way. ucto - Unicode-aware regular-expression based tokenizer for various languages. Tool and C++ library. Supports FoLiA format. libfolia - C++ library for the FoLiA format frog - Memory-based NLP suite developed for Dutch: PoS tagger, lemmatiser, dependency parser, NER, shallow parser, morphological analyzer. MeTA - MeTA : ModErn Text Analysis is a C++ Data Sciences Toolkit that facilitates mining big text data. Mecab (Japanese) Moses StarSpace - a library from Facebook for creating embeddings of word-level, paragraph-level, document-level and for text classification Java \u00b6 Java NLP \u5e93 Stanford NLP OpenNLP NLP4J Word2vec in Java ReVerb Web-Scale Open Information Extraction OpenRegex An efficient and flexible token-based regular expression language and engine. CogcompNLP - Core libraries developed in the U of Illinois' Cognitive Computation Group. MALLET - MAchine Learning for LanguagE Toolkit - package for statistical natural language processing, document classification, clustering, topic modeling, information extraction, and other machine learning applications to text. RDRPOSTagger - A robust POS tagging toolkit available (in both Java & Python) together with pre-trained models for 40+ languages. Kotlin \u00b6 Kotlin NLP \u5e93 Lingua A language detection library for Kotlin and Java, suitable for long and short text alike Kotidgy \u2014 an index-based text data generator written in Kotlin Scala \u00b6 Scala NLP \u5e93 Saul - Library for developing NLP systems, including built in modules like SRL, POS, etc. ATR4S - Toolkit with state-of-the-art automatic term recognition methods. tm - Implementation of topic modeling based on regularized multilingual PLSA . word2vec-scala - Scala interface to word2vec model; includes operations on vectors like word-distance and word-analogy. Epic - Epic is a high performance statistical parser written in Scala, along with a framework for building complex structured prediction models. R \u00b6 R NLP \u5e93 text2vec - Fast vectorization, topic modeling, distances and GloVe word embeddings in R. wordVectors - An R package for creating and exploring word2vec and other word embedding models RMallet - R package to interface with the Java machine learning tool MALLET dfr-browser - Creates d3 visualizations for browsing topic models of text in a web browser. dfrtopics - R package for exploring topic models of text. sentiment_classifier - Sentiment Classification using Word Sense Disambiguation and WordNet Reader jProcessing - Japanese Natural Langauge Processing Libraries, with Japanese sentiment classification Clojure \u00b6 Clojure-openNLP - Natural Language Processing in Clojure (opennlp) Infections-clj - Rails-like inflection library for Clojure and ClojureScript postagga - A library to parse natural language in Clojure and ClojureScript Ruby \u00b6 Kevin Dias's A collection of Natural Language Processing (NLP) Ruby libraries, tools and software Practical Natural Language Processing done in Ruby Rust \u00b6 whatlang \u2014 \u57fa\u4e8e\u4e09\u5143\u7ec4\u7684\u81ea\u7136\u8bed\u8a00\u8bc6\u522b\u5e93 snips-nlu-rs - \u7528\u4e8e\u610f\u56fe\u89e3\u6790\u7684\u751f\u4ea7\u5c31\u7eea\u5e93 \u670d\u52a1 \u00b6 NLP \u4f5c\u4e3a\u5177\u6709\u66f4\u9ad8\u7ea7\u529f\u80fd\u7684 API\uff0c\u4f8b\u5982 NER\uff0c\u4e3b\u9898\u6807\u8bb0\u7b49 Wit-ai - \u5e94\u7528\u548c\u8bbe\u5907\u7684\u81ea\u7136\u8bed\u8a00\u754c\u9762 IBM Watson \u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3 - API \u548c Github \u6f14\u793a \u4e9a\u9a6c\u900a\u9886\u609f - NLP \u548c ML \u5957\u4ef6\u6db5\u76d6\u4e86\u6700\u5e38\u89c1\u7684\u4efb\u52a1\uff0c\u5982 NER\uff0c\u6807\u8bb0\u548c\u60c5\u611f\u5206\u6790 \u8c37\u6b4c\u4e91\u81ea\u7136\u8bed\u8a00 API - \u81f3\u5c11 9 \u79cd\u8bed\u8a00\u7684\u8bed\u6cd5\u5206\u6790\uff0cNER\uff0c\u60c5\u611f\u5206\u6790\u548c\u5185\u5bb9\u6807\u8bb0\u5305\u62ec\u82f1\u8bed\u548c\u4e2d\u6587 (\u7b80\u4f53\u548c\u7e41\u4f53). \u5e73\u884c\u70b9 - \u9ad8\u7ea7\u6587\u672c\u5206\u6790 API \u670d\u52a1\uff0c\u4ece\u60c5\u611f\u5206\u6790\u5230\u610f\u56fe\u5206\u6790 Microsoft \u8ba4\u77e5\u670d\u52a1 \u6587\u5b57\u5243\u5200 \u7f57\u585e\u7279 \u6ce8\u91ca\u5de5\u5177 \u00b6 GATE - \u901a\u7528\u67b6\u6784\u548c\u6587\u672c\u5de5\u7a0b\u5df2\u6709 15 \u5e74\u5386\u53f2\uff0c\u514d\u8d39\u548c\u5f00\u6e90 Anafora \u662f\u514d\u8d39\u7684\u5f00\u6e90\uff0c\u57fa\u4e8e Web \u7684\u539f\u59cb\u6587\u672c\u6ce8\u91ca\u5de5\u5177 brat - brat rapid annotation tool \u662f\u4e00\u4e2a\u7528\u4e8e\u534f\u4f5c\u6587\u672c\u6ce8\u91ca\u7684\u5728\u7ebf\u73af\u5883 tagtog , costs \\$ prodigy \u662f\u4e00\u79cd\u7531\u4e3b\u52a8\u5b66\u4e60\u63d0\u4f9b\u652f\u6301\u7684\u6ce8\u91ca\u5de5\u5177, costs \\$ LightTag - \u4e3a\u56e2\u961f\u63d0\u4f9b\u6258\u7ba1\u548c\u7ba1\u7406\u7684\u6587\u672c\u6ce8\u91ca\u5de5\u5177, costs \\$","title":"\u5e93"},{"location":"awesome/libraries/#_1","text":"","title":"\u5e93"},{"location":"awesome/libraries/#_2","text":"","title":"\u8bed\u8a00\u5e93"},{"location":"awesome/libraries/#nodejs-javascript","text":"Node.js NLP \u7684\u5e93 Twitter-text - Twitter \u7684\u6587\u672c\u5904\u7406\u5e93\u7684 JavaScript \u5b9e\u73b0 Knwl.js - JS \u4e2d\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5668 Retext - \u7528\u4e8e\u5206\u6790\u548c\u64cd\u7eb5\u81ea\u7136\u8bed\u8a00\u7684\u53ef\u6269\u5c55\u7cfb\u7edf NLP Compromise - \u6d4f\u89c8\u5668\u4e2d\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406 Natural - \u8282\u70b9\u7684\u4e00\u822c\u81ea\u7136\u8bed\u8a00\u8bbe\u65bd Poplar - \u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u7684\u57fa\u4e8e Web \u7684\u6ce8\u91ca\u5de5\u5177","title":"Node.js \u548c Javascript"},{"location":"awesome/libraries/#python","text":"Python NLP \u5e93 TextBlob - Providing a consistent API for diving into common natural language processing (NLP) tasks. Stands on the giant shoulders of Natural Language Toolkit (NLTK) and Pattern , and plays nicely with both :+1: spaCy - Industrial strength NLP with Python and Cython :+1: textacy - Higher level NLP built on spaCy gensim - Python library to conduct unsupervised semantic modelling from plain text :+1: scattertext - Python library to produce d3 visualizations of how language differs between corpora AllenNLP - An NLP research library, built on PyTorch, for developing state-of-the-art deep learning models on a wide variety of linguistic tasks. PyTorch-NLP - NLP research toolkit designed to support rapid prototyping with better data loaders, word vector loaders, neural network layer representations, common NLP metrics such as BLEU Rosetta - Text processing tools and wrappers (e.g. Vowpal Wabbit) PyNLPl - Python Natural Language Processing Library. General purpose NLP library for Python. Also contains some specific modules for parsing common NLP formats, most notably for FoLiA , but also ARPA language models, Moses phrasetables, GIZA++ alignments. jPTDP - A toolkit for joint part-of-speech (POS) tagging and dependency parsing. jPTDP provides pre-trained models for 40+ languages. BigARTM - a fast library for topic modelling Snips NLU - A production ready library for intent parsing Chazutsu - A library for downloading&parsing standard NLP research datasets Word Forms - Word forms can accurately generate all possible forms of an English word Multilingual Latent Dirichlet Allocation (LDA) - A multilingual and extensible document clustering pipeline NLP Architect - A library for exploring the state-of-the-art deep learning topologies and techniques for NLP and NLU Flair - A very simple framework for state-of-the-art multilingual NLP built on PyTorch. Includes BERT, ELMo and Flair embeddings. Kashgari - Simple, Keras-powered multilingual NLP framework, allows you to build your models in 5 minutes for named entity recognition (NER), part-of-speech tagging (PoS) and text classification tasks. Includes BERT and word2vec embedding.","title":"Python"},{"location":"awesome/libraries/#c","text":"C++ \u5e93 MIT Information Extraction Toolkit - C, C++, and Python tools for named entity recognition and relation extraction CRF++ - Open source implementation of Conditional Random Fields (CRFs) for segmenting/labeling sequential data & other Natural Language Processing tasks. CRFsuite - CRFsuite is an implementation of Conditional Random Fields (CRFs) for labeling sequential data. BLLIP Parser - BLLIP Natural Language Parser (also known as the Charniak-Johnson parser) colibri-core - C++ library, command line tools, and Python binding for extracting and working with basic linguistic constructions such as n-grams and skipgrams in a quick and memory-efficient way. ucto - Unicode-aware regular-expression based tokenizer for various languages. Tool and C++ library. Supports FoLiA format. libfolia - C++ library for the FoLiA format frog - Memory-based NLP suite developed for Dutch: PoS tagger, lemmatiser, dependency parser, NER, shallow parser, morphological analyzer. MeTA - MeTA : ModErn Text Analysis is a C++ Data Sciences Toolkit that facilitates mining big text data. Mecab (Japanese) Moses StarSpace - a library from Facebook for creating embeddings of word-level, paragraph-level, document-level and for text classification","title":"C++"},{"location":"awesome/libraries/#java","text":"Java NLP \u5e93 Stanford NLP OpenNLP NLP4J Word2vec in Java ReVerb Web-Scale Open Information Extraction OpenRegex An efficient and flexible token-based regular expression language and engine. CogcompNLP - Core libraries developed in the U of Illinois' Cognitive Computation Group. MALLET - MAchine Learning for LanguagE Toolkit - package for statistical natural language processing, document classification, clustering, topic modeling, information extraction, and other machine learning applications to text. RDRPOSTagger - A robust POS tagging toolkit available (in both Java & Python) together with pre-trained models for 40+ languages.","title":"Java"},{"location":"awesome/libraries/#kotlin","text":"Kotlin NLP \u5e93 Lingua A language detection library for Kotlin and Java, suitable for long and short text alike Kotidgy \u2014 an index-based text data generator written in Kotlin","title":"Kotlin"},{"location":"awesome/libraries/#scala","text":"Scala NLP \u5e93 Saul - Library for developing NLP systems, including built in modules like SRL, POS, etc. ATR4S - Toolkit with state-of-the-art automatic term recognition methods. tm - Implementation of topic modeling based on regularized multilingual PLSA . word2vec-scala - Scala interface to word2vec model; includes operations on vectors like word-distance and word-analogy. Epic - Epic is a high performance statistical parser written in Scala, along with a framework for building complex structured prediction models.","title":"Scala"},{"location":"awesome/libraries/#r","text":"R NLP \u5e93 text2vec - Fast vectorization, topic modeling, distances and GloVe word embeddings in R. wordVectors - An R package for creating and exploring word2vec and other word embedding models RMallet - R package to interface with the Java machine learning tool MALLET dfr-browser - Creates d3 visualizations for browsing topic models of text in a web browser. dfrtopics - R package for exploring topic models of text. sentiment_classifier - Sentiment Classification using Word Sense Disambiguation and WordNet Reader jProcessing - Japanese Natural Langauge Processing Libraries, with Japanese sentiment classification","title":"R"},{"location":"awesome/libraries/#clojure","text":"Clojure-openNLP - Natural Language Processing in Clojure (opennlp) Infections-clj - Rails-like inflection library for Clojure and ClojureScript postagga - A library to parse natural language in Clojure and ClojureScript","title":"Clojure"},{"location":"awesome/libraries/#ruby","text":"Kevin Dias's A collection of Natural Language Processing (NLP) Ruby libraries, tools and software Practical Natural Language Processing done in Ruby","title":"Ruby"},{"location":"awesome/libraries/#rust","text":"whatlang \u2014 \u57fa\u4e8e\u4e09\u5143\u7ec4\u7684\u81ea\u7136\u8bed\u8a00\u8bc6\u522b\u5e93 snips-nlu-rs - \u7528\u4e8e\u610f\u56fe\u89e3\u6790\u7684\u751f\u4ea7\u5c31\u7eea\u5e93","title":"Rust"},{"location":"awesome/libraries/#_3","text":"NLP \u4f5c\u4e3a\u5177\u6709\u66f4\u9ad8\u7ea7\u529f\u80fd\u7684 API\uff0c\u4f8b\u5982 NER\uff0c\u4e3b\u9898\u6807\u8bb0\u7b49 Wit-ai - \u5e94\u7528\u548c\u8bbe\u5907\u7684\u81ea\u7136\u8bed\u8a00\u754c\u9762 IBM Watson \u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3 - API \u548c Github \u6f14\u793a \u4e9a\u9a6c\u900a\u9886\u609f - NLP \u548c ML \u5957\u4ef6\u6db5\u76d6\u4e86\u6700\u5e38\u89c1\u7684\u4efb\u52a1\uff0c\u5982 NER\uff0c\u6807\u8bb0\u548c\u60c5\u611f\u5206\u6790 \u8c37\u6b4c\u4e91\u81ea\u7136\u8bed\u8a00 API - \u81f3\u5c11 9 \u79cd\u8bed\u8a00\u7684\u8bed\u6cd5\u5206\u6790\uff0cNER\uff0c\u60c5\u611f\u5206\u6790\u548c\u5185\u5bb9\u6807\u8bb0\u5305\u62ec\u82f1\u8bed\u548c\u4e2d\u6587 (\u7b80\u4f53\u548c\u7e41\u4f53). \u5e73\u884c\u70b9 - \u9ad8\u7ea7\u6587\u672c\u5206\u6790 API \u670d\u52a1\uff0c\u4ece\u60c5\u611f\u5206\u6790\u5230\u610f\u56fe\u5206\u6790 Microsoft \u8ba4\u77e5\u670d\u52a1 \u6587\u5b57\u5243\u5200 \u7f57\u585e\u7279","title":"\u670d\u52a1"},{"location":"awesome/libraries/#_4","text":"GATE - \u901a\u7528\u67b6\u6784\u548c\u6587\u672c\u5de5\u7a0b\u5df2\u6709 15 \u5e74\u5386\u53f2\uff0c\u514d\u8d39\u548c\u5f00\u6e90 Anafora \u662f\u514d\u8d39\u7684\u5f00\u6e90\uff0c\u57fa\u4e8e Web \u7684\u539f\u59cb\u6587\u672c\u6ce8\u91ca\u5de5\u5177 brat - brat rapid annotation tool \u662f\u4e00\u4e2a\u7528\u4e8e\u534f\u4f5c\u6587\u672c\u6ce8\u91ca\u7684\u5728\u7ebf\u73af\u5883 tagtog , costs \\$ prodigy \u662f\u4e00\u79cd\u7531\u4e3b\u52a8\u5b66\u4e60\u63d0\u4f9b\u652f\u6301\u7684\u6ce8\u91ca\u5de5\u5177, costs \\$ LightTag - \u4e3a\u56e2\u961f\u63d0\u4f9b\u6258\u7ba1\u548c\u7ba1\u7406\u7684\u6587\u672c\u6ce8\u91ca\u5de5\u5177, costs \\$","title":"\u6ce8\u91ca\u5de5\u5177"},{"location":"awesome/multi-language/","text":"\u5176\u4ed6\u8bed\u8a00 \u00b6 \u591a\u8bed\u79cd NLP \u6846\u67b6 \u00b6 UDPipe is a trainable pipeline for tokenizing, tagging, lemmatizing and parsing Universal Treebanks and other CoNLL-U files. Primarily written in C++, offers a fast and reliable solution for multilingual NLP processing. NLP-Cube : Natural Language Processing Pipeline - Sentence Splitting, Tokenization, Lemmatization, Part-of-speech Tagging and Dependency Parsing. New platform, written in Python with Dynet 2.0. Offers standalone (CLI/Python bindings) and server functionality (REST API). NLP-\u97e9\u8bed \u00b6 \u5e93 \u00b6 KoNLPy - Python package for Korean natural language processing. Mecab (Korean) - C++ library for Korean NLP KoalaNLP - Scala library for Korean Natural Language Processing. KoNLP - R package for Korean Natural language processing \u535a\u5ba2\u548c\u6559\u7a0b \u00b6 dsindex's blog Kangwon University's NLP course in Korean \u6570\u636e\u96c6 \u00b6 KAIST Corpus - A corpus from the Korea Advanced Institute of Science and Technology in Korean. Naver Sentiment Movie Corpus in Korean Chosun Ilbo archive - dataset in Korean from one of the major newspapers in South Korea, the Chosun Ilbo. NLP-\u963f\u62c9\u4f2f\u8bed \u00b6 \u5e93 \u00b6 goarabic - Go package for Arabic text processing jsastem - Javascript for Arabic stemming PyArabic - Python libraries for Arabic \u6570\u636e\u96c6 \u00b6 Multidomain Datasets - Largest Available Multi-Domain Resources for Arabic Sentiment Analysis LABR - LArge Arabic Book Reviews dataset Arabic Stopwords - A list of Arabic stopwords from various resources NLP-\u4e2d\u6587 \u00b6 \u5e93 \u00b6 jieba - Python package for Words Segmentation Utilities in Chinese SnowNLP - Python package for Chinese NLP FudanNLP - Java library for Chinese text processing NLP-\u5fb7\u8bed \u00b6 German-NLP - Curated list of open-access/open-source/off-the-shelf resources and tools developed with a particular focus on German NLP-\u897f\u73ed\u7259\u8bed \u00b6 \u6570\u636e \u00b6 Columbian Political Speeches Copenhagen Treebank Spanish Billion words corpus with Word2Vec embeddings NLP-\u5370\u5ea6\u8bed \u00b6 Hindi \u00b6 Data, Corpora and Treebanks \u00b6 Hindi Dependency Treebank - A multi-representational multi-layered treebank for Hindi and Urdu Universal Dependencies Treebank in Hindi Parallel Universal Dependencies Treebank in Hindi - A smaller part of the above-mentioned treebank. NLP-\u6cf0\u8bed \u00b6 \u5e93 \u00b6 PyThaiNLP - Thai NLP in Python Package JTCC - A character cluster library in Java CutKum - Word segmentation with deep learning in TensorFlow Thai Language Toolkit - Based on a paper by Wirote Aroonmanakun in 2002 with included dataset SynThai - Word segmentation and POS tagging using deep learning in Python \u6570\u636e \u00b6 Inter-BEST - A text corpus with 5 million words with word segmentation Prime Minister 29 - Dataset containing speeches of the current Prime Minister of Thailand NLP-\u4e39\u9ea6\u8bed \u00b6 Named Entity Recognition for Danish NLP-\u8d8a\u5357\u8bed \u00b6 \u5e93 \u00b6 underthesea - Vietnamese NLP Toolkit vn.vitk - A Vietnamese Text Processing Toolkit VnCoreNLP - A Vietnamese natural language processing toolkit \u6570\u636e \u00b6 Vietnamese treebank - 10,000 sentences for the constituency parsing task BKTreeBank - a Vietnamese Dependency Treebank UD_Vietnamese - Vietnamese Universal Dependency Treebank VIVOS - a free Vietnamese speech corpus consisting of 15 hours of recording speech by AILab VNTQcorpus(big).txt - 1.75 million sentences in news NLP-\u5370\u5ea6\u5c3c\u897f\u4e9a\u8bed \u00b6 \u6570\u636e\u96c6 \u00b6 Kompas and Tempo collections at ILPS PANL10N for PoS tagging : 39K sentences and 900K word tokens IDN for PoS tagging : This corpus contains 10K sentences and 250K word tokens Indonesian Treebank and Universal Dependencies-Indonesian IndoSum for text summarization and classification both Wordnet-Bahasa - large, free, semantic dictionary \u5e93\u548c\u5d4c\u5165 \u00b6 Natural language toolkit bahasa Indonesian Word Embedding Pretrained Indonesian fastText Text Embedding trained on Wikipedia \u5176\u4ed6\u8bed\u8a00 \u00b6 \u4fc4\u8bed: pymorphy2 - a good pos-tagger for Russian \u4e9a\u6d32\u8bed\u8a00: \u6cf0\u56fd, Lao, \u4e2d\u6587, \u65e5\u672c, \u548c\u97e9\u56fd ICU Tokenizer implementation in ElasticSearch \u53e4\u4ee3\u8bed\u8a00: CLTK : The Classical Language Toolkit is a Python library and collection of texts for doing NLP in ancient languages \u8377\u5170\u8bed: python-frog - Python binding to Frog, an NLP suite for Dutch. (pos tagging, lemmatisation, dependency parsing, NER) \u5e0c\u4f2f\u6765\u8bed: NLPH_Resources - A collection of papers, corpora and linguistic resources for NLP in Hebrew","title":"\u5176\u4ed6\u8bed\u8a00"},{"location":"awesome/multi-language/#_1","text":"","title":"\u5176\u4ed6\u8bed\u8a00"},{"location":"awesome/multi-language/#nlp","text":"UDPipe is a trainable pipeline for tokenizing, tagging, lemmatizing and parsing Universal Treebanks and other CoNLL-U files. Primarily written in C++, offers a fast and reliable solution for multilingual NLP processing. NLP-Cube : Natural Language Processing Pipeline - Sentence Splitting, Tokenization, Lemmatization, Part-of-speech Tagging and Dependency Parsing. New platform, written in Python with Dynet 2.0. Offers standalone (CLI/Python bindings) and server functionality (REST API).","title":"\u591a\u8bed\u79cd NLP \u6846\u67b6"},{"location":"awesome/multi-language/#nlp-","text":"","title":"NLP-\u97e9\u8bed"},{"location":"awesome/multi-language/#_2","text":"KoNLPy - Python package for Korean natural language processing. Mecab (Korean) - C++ library for Korean NLP KoalaNLP - Scala library for Korean Natural Language Processing. KoNLP - R package for Korean Natural language processing","title":"\u5e93"},{"location":"awesome/multi-language/#_3","text":"dsindex's blog Kangwon University's NLP course in Korean","title":"\u535a\u5ba2\u548c\u6559\u7a0b"},{"location":"awesome/multi-language/#_4","text":"KAIST Corpus - A corpus from the Korea Advanced Institute of Science and Technology in Korean. Naver Sentiment Movie Corpus in Korean Chosun Ilbo archive - dataset in Korean from one of the major newspapers in South Korea, the Chosun Ilbo.","title":"\u6570\u636e\u96c6"},{"location":"awesome/multi-language/#nlp-_1","text":"","title":"NLP-\u963f\u62c9\u4f2f\u8bed"},{"location":"awesome/multi-language/#_5","text":"goarabic - Go package for Arabic text processing jsastem - Javascript for Arabic stemming PyArabic - Python libraries for Arabic","title":"\u5e93"},{"location":"awesome/multi-language/#_6","text":"Multidomain Datasets - Largest Available Multi-Domain Resources for Arabic Sentiment Analysis LABR - LArge Arabic Book Reviews dataset Arabic Stopwords - A list of Arabic stopwords from various resources","title":"\u6570\u636e\u96c6"},{"location":"awesome/multi-language/#nlp-_2","text":"","title":"NLP-\u4e2d\u6587"},{"location":"awesome/multi-language/#_7","text":"jieba - Python package for Words Segmentation Utilities in Chinese SnowNLP - Python package for Chinese NLP FudanNLP - Java library for Chinese text processing","title":"\u5e93"},{"location":"awesome/multi-language/#nlp-_3","text":"German-NLP - Curated list of open-access/open-source/off-the-shelf resources and tools developed with a particular focus on German","title":"NLP-\u5fb7\u8bed"},{"location":"awesome/multi-language/#nlp-_4","text":"","title":"NLP-\u897f\u73ed\u7259\u8bed"},{"location":"awesome/multi-language/#_8","text":"Columbian Political Speeches Copenhagen Treebank Spanish Billion words corpus with Word2Vec embeddings","title":"\u6570\u636e"},{"location":"awesome/multi-language/#nlp-_5","text":"","title":"NLP-\u5370\u5ea6\u8bed"},{"location":"awesome/multi-language/#hindi","text":"","title":"Hindi"},{"location":"awesome/multi-language/#data-corpora-and-treebanks","text":"Hindi Dependency Treebank - A multi-representational multi-layered treebank for Hindi and Urdu Universal Dependencies Treebank in Hindi Parallel Universal Dependencies Treebank in Hindi - A smaller part of the above-mentioned treebank.","title":"Data, Corpora and Treebanks"},{"location":"awesome/multi-language/#nlp-_6","text":"","title":"NLP-\u6cf0\u8bed"},{"location":"awesome/multi-language/#_9","text":"PyThaiNLP - Thai NLP in Python Package JTCC - A character cluster library in Java CutKum - Word segmentation with deep learning in TensorFlow Thai Language Toolkit - Based on a paper by Wirote Aroonmanakun in 2002 with included dataset SynThai - Word segmentation and POS tagging using deep learning in Python","title":"\u5e93"},{"location":"awesome/multi-language/#_10","text":"Inter-BEST - A text corpus with 5 million words with word segmentation Prime Minister 29 - Dataset containing speeches of the current Prime Minister of Thailand","title":"\u6570\u636e"},{"location":"awesome/multi-language/#nlp-_7","text":"Named Entity Recognition for Danish","title":"NLP-\u4e39\u9ea6\u8bed"},{"location":"awesome/multi-language/#nlp-_8","text":"","title":"NLP-\u8d8a\u5357\u8bed"},{"location":"awesome/multi-language/#_11","text":"underthesea - Vietnamese NLP Toolkit vn.vitk - A Vietnamese Text Processing Toolkit VnCoreNLP - A Vietnamese natural language processing toolkit","title":"\u5e93"},{"location":"awesome/multi-language/#_12","text":"Vietnamese treebank - 10,000 sentences for the constituency parsing task BKTreeBank - a Vietnamese Dependency Treebank UD_Vietnamese - Vietnamese Universal Dependency Treebank VIVOS - a free Vietnamese speech corpus consisting of 15 hours of recording speech by AILab VNTQcorpus(big).txt - 1.75 million sentences in news","title":"\u6570\u636e"},{"location":"awesome/multi-language/#nlp-_9","text":"","title":"NLP-\u5370\u5ea6\u5c3c\u897f\u4e9a\u8bed"},{"location":"awesome/multi-language/#_13","text":"Kompas and Tempo collections at ILPS PANL10N for PoS tagging : 39K sentences and 900K word tokens IDN for PoS tagging : This corpus contains 10K sentences and 250K word tokens Indonesian Treebank and Universal Dependencies-Indonesian IndoSum for text summarization and classification both Wordnet-Bahasa - large, free, semantic dictionary","title":"\u6570\u636e\u96c6"},{"location":"awesome/multi-language/#_14","text":"Natural language toolkit bahasa Indonesian Word Embedding Pretrained Indonesian fastText Text Embedding trained on Wikipedia","title":"\u5e93\u548c\u5d4c\u5165"},{"location":"awesome/multi-language/#_15","text":"\u4fc4\u8bed: pymorphy2 - a good pos-tagger for Russian \u4e9a\u6d32\u8bed\u8a00: \u6cf0\u56fd, Lao, \u4e2d\u6587, \u65e5\u672c, \u548c\u97e9\u56fd ICU Tokenizer implementation in ElasticSearch \u53e4\u4ee3\u8bed\u8a00: CLTK : The Classical Language Toolkit is a Python library and collection of texts for doing NLP in ancient languages \u8377\u5170\u8bed: python-frog - Python binding to Frog, an NLP suite for Dutch. (pos tagging, lemmatisation, dependency parsing, NER) \u5e0c\u4f2f\u6765\u8bed: NLPH_Resources - A collection of papers, corpora and linguistic resources for NLP in Hebrew","title":"\u5176\u4ed6\u8bed\u8a00"},{"location":"awesome/techniques/","text":"\u6280\u672f \u00b6 \u6587\u5b57\u5d4c\u5165 \u00b6 Text embeddings allow deep learning to be effective on smaller datasets. These are often first inputs to a deep learning archiectures and most popular way of transfer learning in NLP. Embeddings are simply vectors or a more generically, real valued representations of strings. Word embeddings are considered a great starting point for most deep NLP tasks. The most popular names in word embeddings are word2vec by Google (Mikolov) and GloVe by Stanford (Pennington, Socher and Manning). fastText seems to be a fairly popular for multi-lingual sub-word embeddings. \u5355\u8bcd\u5d4c\u5165 \u00b6 Embedding Paper Organisation gensim- Training Support Blogs word2vec Official Implementation , T.Mikolove et al. 2013. Distributed Representations of Words and Phrases and their Compositionality. pdf Google Yes :heavy_check_mark: Visual explanations by colah at Deep Learning, NLP, and Representations ; gensim's Making Sense of word2vec GloVe Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. pdf Stanford No :negative_squared_cross_mark: Morning Paper on GloVe by acoyler fastText Official Implementation , T. Mikolov et al. 2017. Enriching Word Vectors with Subword Information. pdf Facebook Yes :heavy_check_mark: Fasttext: Under the Hood Notes for Beginners: Thumb Rule: fastText >> GloVe > word2vec You can find pre-trained fasttext Vectors in several languages If you are interested in the logic and intuition behind word2vec and GloVe: The Amazing Power of Word Vectors and introduce the topics well arXiv: Bag of Tricks for Efficient Text Classification , and arXiv: FastText.zip: Compressing text classification models were released as part of fasttext \u57fa\u4e8e\u53e5\u5b50\u548c\u8bed\u8a00\u6a21\u578b\u7684\u8bcd\u5d4c\u5165 \u00b6 ElMo from Deep Contextualized Word Represenations - PyTorch implmentation - TF Implementation ULimFit aka Universal Language Model Fine-tuning for Text Classification by Jeremy Howard and Sebastian Ruder InferSent from Supervised Learning of Universal Sentence Representations from Natural Language Inference Data by facebook CoVe from Learned in Translation: Contextualized Word Vectors Pargraph vectors from Distributed Representations of Sentences and Documents . See doc2vec tutorial at gensim sense2vec - on word sense disambiguation Skip Thought Vectors - word representation method Adaptive skip-gram - similar approach, with adaptive properties Sequence to Sequence Learning - word vectors for machine translation \u95ee\u7b54\u548c\u77e5\u8bc6\u63d0\u53d6 \u00b6 DrQA: Open Domain Question Answering by facebook on Wikipedia data DocQA: Simple and Effective Multi-Paragraph Reading Comprehension by AllenAI Markov Logic Networks for Natural Language Question Answering Template-Based Information Extraction without the Templates Relation extraction with matrix factorization and universal schemas Privee: An Architecture for Automatically Analyzing Web Privacy Policies Teaching Machines to Read and Comprehend - DeepMind paper Relation Extraction with Matrix Factorization and Universal Schemas Towards a Formal Distributional Semantics: Simulating Logical Calculi with Tensors Presentation slides for MLN tutorial Presentation slides for QA applications of MLNs Presentation slides","title":"\u6280\u672f"},{"location":"awesome/techniques/#_1","text":"","title":"\u6280\u672f"},{"location":"awesome/techniques/#_2","text":"Text embeddings allow deep learning to be effective on smaller datasets. These are often first inputs to a deep learning archiectures and most popular way of transfer learning in NLP. Embeddings are simply vectors or a more generically, real valued representations of strings. Word embeddings are considered a great starting point for most deep NLP tasks. The most popular names in word embeddings are word2vec by Google (Mikolov) and GloVe by Stanford (Pennington, Socher and Manning). fastText seems to be a fairly popular for multi-lingual sub-word embeddings.","title":"\u6587\u5b57\u5d4c\u5165"},{"location":"awesome/techniques/#_3","text":"Embedding Paper Organisation gensim- Training Support Blogs word2vec Official Implementation , T.Mikolove et al. 2013. Distributed Representations of Words and Phrases and their Compositionality. pdf Google Yes :heavy_check_mark: Visual explanations by colah at Deep Learning, NLP, and Representations ; gensim's Making Sense of word2vec GloVe Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. pdf Stanford No :negative_squared_cross_mark: Morning Paper on GloVe by acoyler fastText Official Implementation , T. Mikolov et al. 2017. Enriching Word Vectors with Subword Information. pdf Facebook Yes :heavy_check_mark: Fasttext: Under the Hood Notes for Beginners: Thumb Rule: fastText >> GloVe > word2vec You can find pre-trained fasttext Vectors in several languages If you are interested in the logic and intuition behind word2vec and GloVe: The Amazing Power of Word Vectors and introduce the topics well arXiv: Bag of Tricks for Efficient Text Classification , and arXiv: FastText.zip: Compressing text classification models were released as part of fasttext","title":"\u5355\u8bcd\u5d4c\u5165"},{"location":"awesome/techniques/#_4","text":"ElMo from Deep Contextualized Word Represenations - PyTorch implmentation - TF Implementation ULimFit aka Universal Language Model Fine-tuning for Text Classification by Jeremy Howard and Sebastian Ruder InferSent from Supervised Learning of Universal Sentence Representations from Natural Language Inference Data by facebook CoVe from Learned in Translation: Contextualized Word Vectors Pargraph vectors from Distributed Representations of Sentences and Documents . See doc2vec tutorial at gensim sense2vec - on word sense disambiguation Skip Thought Vectors - word representation method Adaptive skip-gram - similar approach, with adaptive properties Sequence to Sequence Learning - word vectors for machine translation","title":"\u57fa\u4e8e\u53e5\u5b50\u548c\u8bed\u8a00\u6a21\u578b\u7684\u8bcd\u5d4c\u5165"},{"location":"awesome/techniques/#_5","text":"DrQA: Open Domain Question Answering by facebook on Wikipedia data DocQA: Simple and Effective Multi-Paragraph Reading Comprehension by AllenAI Markov Logic Networks for Natural Language Question Answering Template-Based Information Extraction without the Templates Relation extraction with matrix factorization and universal schemas Privee: An Architecture for Automatically Analyzing Web Privacy Policies Teaching Machines to Read and Comprehend - DeepMind paper Relation Extraction with Matrix Factorization and Universal Schemas Towards a Formal Distributional Semantics: Simulating Logical Calculi with Tensors Presentation slides for MLN tutorial Presentation slides for QA applications of MLNs Presentation slides","title":"\u95ee\u7b54\u548c\u77e5\u8bc6\u63d0\u53d6"},{"location":"awesome/tutorials/","text":"\u6559\u7a0b \u00b6 \u9605\u8bfb\u5185\u5bb9 \u00b6 General Machine Learning Jason's Machine Learning 101 from Google's Senior Creative Engineer explains Machine Learning for engineer's and executives alike a16z AI Playbook is a great link to forward to your managers or content for your presentations Machine Learning Blog by Brian McFee Ruder's Blog by Sebastian Ruder for commentary on the best of NLP Research Introductions and Guides to NLP Ultimate Guide to Understand & Implement Natural Language Processing Introduction to NLP at Hackernoon is for people who suck at math - in their own words NLP Tutorial by Vik Paruchari Natural Language Processing: An Introduction by Oxford Deep Learning for NLP with Pytorch Hands-On NLTK Tutorial - The hands-on NLTK tutorial in the form of Jupyter notebooks Blogs and Newsletters Blog: Deep Learning, NLP, and Representations Blog: The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) and The Illustrated Transformer Blog: Natural Language Processing by Hal Daum\u00e9 III Tutorials by Radim \u0158eh\u016f\u0159ek on using Python and gensim to process language corpora arXiv: Natural Language Processing (Almost) from Scratch Karpathy's The Unreasonable Effectiveness of Recurrent Neural Networks \u89c6\u9891\u548c\u5728\u7ebf\u8bfe\u7a0b \u00b6 \u6df1\u5ea6\u5b66\u4e60\u548c NLP \u00b6 Word embeddings, RNNs, LSTMs and CNNs for Natural Language Processing | Udacity's Intro to Artificial Intelligence course which touches upon NLP as well Udacity's Deep Learning using Tensorflow which covers a section on using deep learning for NLP tasks (covering Word2Vec, RNN's and LSTMs) Oxford's Deep Natural Language Processing has videos, lecture slides and reading material Stanford's Deep Learning for Natural Language Processing (cs224-n) by Richard Socher and Christopher Manning Coursera's Natural Language Processing by National Research University Higher School of Economics Carnegie Mellon University's Neural Networks for NLP by Language Technology Institute there \u7ecf\u5178 NLP \u00b6 Bayesian, statistics and Linguistics approaches for Natural Language Processing | Statistical Machine Translation - a Machine Translation course with great assignments and slides NLTK with Python 3 for Natural Language Processing by Harrison Kinsley(sentdex). Good tutorials with NLTK code implementation Computational Linguistics I by Jordan Boyd-Graber, Lectures from University of Maryland Deep NLP Course by Yandex Data School, covering important ideas from text embedding to machine translation including sequence modeling, language models and so on. \u56fe\u4e66 \u00b6 Speech and Language Processing by Prof. Dan Jurafsy Text Mining in R Natural Language Processing with Python","title":"\u6559\u7a0b"},{"location":"awesome/tutorials/#_1","text":"","title":"\u6559\u7a0b"},{"location":"awesome/tutorials/#_2","text":"General Machine Learning Jason's Machine Learning 101 from Google's Senior Creative Engineer explains Machine Learning for engineer's and executives alike a16z AI Playbook is a great link to forward to your managers or content for your presentations Machine Learning Blog by Brian McFee Ruder's Blog by Sebastian Ruder for commentary on the best of NLP Research Introductions and Guides to NLP Ultimate Guide to Understand & Implement Natural Language Processing Introduction to NLP at Hackernoon is for people who suck at math - in their own words NLP Tutorial by Vik Paruchari Natural Language Processing: An Introduction by Oxford Deep Learning for NLP with Pytorch Hands-On NLTK Tutorial - The hands-on NLTK tutorial in the form of Jupyter notebooks Blogs and Newsletters Blog: Deep Learning, NLP, and Representations Blog: The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) and The Illustrated Transformer Blog: Natural Language Processing by Hal Daum\u00e9 III Tutorials by Radim \u0158eh\u016f\u0159ek on using Python and gensim to process language corpora arXiv: Natural Language Processing (Almost) from Scratch Karpathy's The Unreasonable Effectiveness of Recurrent Neural Networks","title":"\u9605\u8bfb\u5185\u5bb9"},{"location":"awesome/tutorials/#_3","text":"","title":"\u89c6\u9891\u548c\u5728\u7ebf\u8bfe\u7a0b"},{"location":"awesome/tutorials/#nlp","text":"Word embeddings, RNNs, LSTMs and CNNs for Natural Language Processing | Udacity's Intro to Artificial Intelligence course which touches upon NLP as well Udacity's Deep Learning using Tensorflow which covers a section on using deep learning for NLP tasks (covering Word2Vec, RNN's and LSTMs) Oxford's Deep Natural Language Processing has videos, lecture slides and reading material Stanford's Deep Learning for Natural Language Processing (cs224-n) by Richard Socher and Christopher Manning Coursera's Natural Language Processing by National Research University Higher School of Economics Carnegie Mellon University's Neural Networks for NLP by Language Technology Institute there","title":"\u6df1\u5ea6\u5b66\u4e60\u548c NLP"},{"location":"awesome/tutorials/#nlp_1","text":"Bayesian, statistics and Linguistics approaches for Natural Language Processing | Statistical Machine Translation - a Machine Translation course with great assignments and slides NLTK with Python 3 for Natural Language Processing by Harrison Kinsley(sentdex). Good tutorials with NLTK code implementation Computational Linguistics I by Jordan Boyd-Graber, Lectures from University of Maryland Deep NLP Course by Yandex Data School, covering important ideas from text embedding to machine translation including sequence modeling, language models and so on.","title":"\u7ecf\u5178 NLP"},{"location":"awesome/tutorials/#_4","text":"Speech and Language Processing by Prof. Dan Jurafsy Text Mining in R Natural Language Processing with Python","title":"\u56fe\u4e66"}]}