自然语言处理
============

   引自维基百科的内容:
   `自然语言处理 <https://zh.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86>`__

自然语言处理（英语：Natural Language Processing，缩写作
NLP）是人工智能和语言学领域的分支学科。此领域探讨如何处理及运用自然语言；自然语言处理包括多方面和步骤，基本有认知、理解、生成等部分。

自然语言认知和理解是让计算机把输入的语言变成有意思的符号和关系，然后根据目的再处理。自然语言生成系统则是把计算机数据转化为自然语言。

历史
----

自然语言处理大体是从 1950 年代开始，虽然更早期也有作为。1950
年，图灵发表论文“计算机器与智能”，提出现在所谓的“图灵测试”作为判断智能的条件。

1954 年的乔治城实验涉及全部自动翻译超过 60
句俄文成为英文。研究人员声称三到五年之内即可解决机器翻译的问题。[1]不过实际进展远低于预期，1966
年的 ALPAC
报告发现十年研究未达预期目标，机器翻译的研究经费遭到大幅削减。一直到
1980
年代末期，统计机器翻译系统发展出来，机器翻译的研究才得以更上一层楼。

1960 年代发展特别成功的 NLP 系统包括
SHRDLU——一个词汇设限、运作于受限如“积木世界”的一种自然语言系统，以及
1964-1966 年约瑟夫·维森鲍姆模拟“个人中心治疗”而设计的
ELIZA——几乎未运用人类思想和感情的消息，有时候却能呈现令人讶异地类似人之间的交互。“病人”提出的问题超出
ELIZA
极小的知识范围之时，可能会得到空泛的回答。例如问题是“我的头痛”，回答是“为什么说你头痛？”

1970 年代，程序员开始设计“概念本体论”（conceptual
ontologies）的程序，将现实世界的信息，架构成计算机能够理解的数据。实例有
MARGIE、SAM、PAM、TaleSpin、QUALM、Politics 以及 Plot
Unit。许多聊天机器人在这一时期写成，包括 PARRY 、Racter 以及 Jabberwacky
。

一直到 1980
年代，多数自然语言处理系统是以一套复杂、人工订定的规则为基础。不过从
1980 年代末期开始，语言处理引进了机器学习的算法，NLP
产生革新。成因有两个：运算能力稳定增加（参见摩尔定律）；以及乔姆斯基
语言学理论渐渐丧失主导（例如转换-生成文法）。该理论的架构不倾向于语料库——机器学习处理语言所用方法的基础。有些最早期使用的机器学习算法，例如决策树，是硬性的、“如果-则”规则组成的系统，类似当时既有的人工订定的规则。不过词性标记将隐马尔可夫模型引入
NLP，并且研究日益聚焦于软性的、以机率做决定的统计模型，基础是将输入数据里每一个特性赋予代表其分量的数值。许多语音识别现今依赖的缓存语言模型即是一种统计模型的例子。这种模型通常足以处理非预期的输入数据，尤其是输入有错误（真实世界的数据总免不了），并且在集成到包含多个子任务的较大系统时，结果比较可靠。

许多早期的成功属于机器翻译领域，尤其归功 IBM
的研究，渐次发展出更复杂的统计模型。这些系统得以利用加拿大和欧盟现有的语料库，因为其法律规定政府的会议必须翻译成所有的官方语言。不过，其他大部分系统必须特别打造自己的语料库，一直到现在这都是限制其成功的一个主要因素，于是大量的研究致力于从有限的数据更有效地学习。

近来的研究更加聚焦于非监督式学习和半监督学习的算法。这种算法，能够从没有人工注解理想答案的数据里学习。大体而言，这种学习比监督学习困难，并且在同量的数据下，通常产生的结果较不准确。不过没有注解的数据量极巨（包含了万维网），弥补了较不准确的缺点。

近年来, 深度学习技巧纷纷出炉[2][3]
在自然语言处理方面获得最尖端的成果，例如语言模型[4]、语法分析[5][6]等等。

##任务和限制 理论上，NLP
是一种很吸引人的人机交互方式。早期的语言处理系统如
SHRDLU，当它们处于一个有限的“积木世界”，运用有限的词汇表会话时，工作得相当好。这使得研究员们对此系统相当乐观，然而，当把这个系统拓展到充满了现实世界的含糊与不确定性的环境中时，他们很快丧失了信心。

由于理解（understanding）自然语言，需要关于外在世界的广泛知识以及运用操作这些知识的能力，自然语言认知，同时也被视为一个人工智能完备（AI-complete）的问题。同时，在自然语言处理中，“理解”的定义也变成一个主要的问题。

实际问题
--------

一些 NLP 面临的问题实例：

句子“我们把香蕉给猴子，因为(牠们)饿了”和“我们把香蕉给猴子，因为(它们)熟透了”有同样的结构。但是代词“它们”在第一句中指的是“猴子”，在第二句中指的是“香蕉”。如果不了解猴子和香蕉的属性，无法区分。(简体中文和英文的它/it
没有区分，但在中文(繁体中文)里「牠」和「它」是有区别的，只是代词在中文里常常被省略，因此需区别属性并且标示出来)

自然语言处理的主要范畴
----------------------

-  文本朗读（Text to speech）/语音合成（Speech synthesis）
-  语音识别（Speech recognition）
-  中文自动分词（Chinese word segmentation）
-  词性标注（Part-of-speech tagging）
-  句法分析（Parsing）
-  自然语言生成（Natural language generation）
-  文本分类（Text categorization）
-  信息检索（Information retrieval）
-  信息抽取（Information extraction）
-  文字校对（Text-proofing）
-  问答系统（Question answering）

   ::

      给一句人类语言的问句，决定其答案。 典型问题有特定答案 (像是加拿大的首都叫什么?)，但也考虑些开放式问句(像是人生的意义是是什么?)

-  机器翻译（Machine translation）

   ::

      将某种人类语言自动翻译至另一种语言

-  自动摘要（Automatic summarization）

   ::

      产生一段文字的大意，通常用于提供已知领域的文章摘要，例如产生报纸上某篇文章之摘要

-  文字蕴涵（Textual entailment）
-  命名实体识别（Named entity recognition）

自然语言处理研究的难点
----------------------

单词的边界界定
~~~~~~~~~~~~~~

在口语中，词与词之间通常是连贯的，而界定字词边界通常使用的办法是取用能让给定的上下文最为通顺且在文法上无误的一种最佳组合。在书写上，汉语也没有词与词之间的边界。

词义的消歧
~~~~~~~~~~

许多字词不单只有一个意思，因而我们必须选出使句意最为通顺的解释。

句法的模糊性
~~~~~~~~~~~~

自然语言的文法通常是模棱两可的，针对一个句子通常可能会剖析（Parse）出多棵剖析树（Parse
Tree），而我们必须要仰赖语义及前后文的信息才能在其中选择一棵最为适合的剖析树。

有瑕疵的或不规范的输入
~~~~~~~~~~~~~~~~~~~~~~

例如语音处理时遇到外国口音或地方口音，或者在文本的处理中处理拼写，语法或者光学字符识别（OCR）的错误。

语言行为与计划
~~~~~~~~~~~~~~

句子常常并不只是字面上的意思；例如，“你能把盐递过来吗”，一个好的回答应当是动手把盐递过去；在大多数上下文环境中，“能”将是糟糕的回答，虽说回答“不”或者“太远了我拿不到”也是可以接受的。再者，如果一门课程去年没开设，对于提问“这门课程去年有多少学生没通过？”回答“去年没开这门课”要比回答“没人没通过”好。

当前自然语言处理研究的发展趋势
------------------------------

第一，传统的基于句法-语义规则的理性主义方法过于复杂，随着语料库建设和语料库语言学的崛起，大规模真实文本的机器学习处理成为自然语言处理的主要选择。

第二，统计数学方法越来越受到重视，自然语言处理中越来越多地使用机器自动学习的方法来获取语言知识。

第三，浅层处理与深层处理并重，统计与规则方法并重，形成混合式的系统。

第四，自然语言处理中越来越重视词汇的作用，出现了强烈的“词汇主义”的倾向。词汇知识库的建造成为了普遍关注的问题。[7]

统计自然语言处理
----------------

统计自然语言处理运用了推测学、机率、统计的方法来解决上述，尤其是针对容易高度模糊的长串句子，当套用实际文法进行分析产生出成千上万笔可能性时所引发之难题。处理这些高度模糊句子所采用消歧的方法通常运用到语料库以及马可夫模型（Markov
models）。统计自然语言处理的技术主要由同样自人工智能下与学习行为相关的子领域：机器学习及数据采掘所演进而成。

相关实例
~~~~~~~~

-  `GATE: a Java Library for Text Engineering <http://gate.ac.uk/>`__
-  `LTP:语言技术平台（简体中文） <http://ir.hit.edu.cn/demo/ltp/>`__
-  `MARF <https://zh.wikipedia.org/wiki/MARF>`__
-  `Python
   编程语言的自然语言处理工具包教程 <http://www.nltk.org/book>`__
-  `fastNLP <https://github.com/fastnlp/fastNLP>`__

延伸阅读
--------

-  贝茨，M。自然语言理解的模型。美利坚合众国国家科学院院刊。
   1995,92（22）：9977-9982。 `DOI：10.1073 /
   pnas.92.22.9977 <https://dx.doi.org/10.1073%2Fpnas.92.22.9977>`__\ 。
-  Steven Bird，Ewan Klein 和 Edward Loper（2009）。 Python
   的自然语言处理。奥莱利媒体。 `ISBN
   978-0-596-51649-9 <https://zh.wikipedia.org/wiki/Special:%E7%BD%91%E7%BB%9C%E4%B9%A6%E6%BA%90/9780596516499>`__\ 。
-  Daniel Jurafsky 和 James H. Martin（2008）。语音和语言处理，第 2
   版。皮尔森普伦蒂斯霍尔。 `ISBN
   978-0-13-187321-6 <https://zh.wikipedia.org/wiki/Special:%E7%BD%91%E7%BB%9C%E4%B9%A6%E6%BA%90/9780131873216>`__\ 。
-  Christopher D. Manning，Prabhakar Raghavan 和
   HinrichSchütze（2008）。信息检索简介。剑桥大学出版社。 `ISBN
   978-0-521-86571-5 <https://zh.wikipedia.org/wiki/Special:%E7%BD%91%E7%BB%9C%E4%B9%A6%E6%BA%90/9780521865715>`__\ 。\ `官方
   html 和 pdf 版本免费提供 <http://nlp.stanford.edu/IR-book/>`__\ 。
-  Christopher D. Manning 和
   HinrichSchütze（1999）。统计自然语言处理的基础。麻省理工学院出版社。
   `ISBN
   978-0-262-13360-9 <https://zh.wikipedia.org/wiki/Special:%E7%BD%91%E7%BB%9C%E4%B9%A6%E6%BA%90/9780262133609>`__\ 。
-  David M. W. Powers 和 Christopher C. R.
   Turk（1989）。自然语言的机器学习。施普林格出版社。 `ISBN
   978-0-387-19557-5 <https://zh.wikipedia.org/wiki/Special:%E7%BD%91%E7%BB%9C%E4%B9%A6%E6%BA%90/9780387195575>`__\ 。

外部链接
--------

-  `人类语言技术当前发展情况概览 <https://web.archive.org/web/20100616131036/http://www.cslu.ogi.edu/HLTsurvey/>`__
-  `哥伦比亚大学自然语言处理研究组 <http://www.cs.columbia.edu/nlp/>`__
-  `卡内基梅隆大学语言技术研究院 <http://www.lti.cs.cmu.edu/>`__
-  `斯坦福大学自然语言处理研究小组 <http://nlp.stanford.edu/>`__
-  `中文自然语言处理开放平台 <http://www.nlp.org.cn/>`__
-  `ACL（美国计算机语言学协会）提供的相关杂志以及研讨会的论文 <https://web.archive.org/web/20040916080945/http://acl.ldc.upenn.edu/>`__
