

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>59. Keras &mdash; nlp-docs v2019.03.19 æ–‡æ¡£</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script type="text/javascript" src="../_static/translations.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
    <link rel="index" title="ç´¢å¼•" href="../genindex.html" />
    <link rel="search" title="æœç´¢" href="../search.html" />
    <link rel="next" title="61. PyTorch" href="PyTorch.html" />
    <link rel="prev" title="58. Jiagu" href="Jiagu.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../contents.html" class="icon icon-home"> nlp-docs
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../info.html">1. è‡ªç„¶è¯­è¨€å¤„ç†</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Author/index.html">2. è‡ªç„¶è¯­è¨€å¤„ç†ä½œè€…</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Algorithm/ConditionalRandomField.html">3. æ¡ä»¶éšæœºåœº CRFï¼ˆConditional Random Fieldï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Algorithm/Hidden_Markov_Model.html">4. éšé©¬å°”å¯å¤«æ¨¡å‹ HMMï¼ˆHidden Markov Modelï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Algorithm/MMSEG.html">5. MMSEG</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Algorithm/MMSeg_description.html">6. MMSeg åˆ†è¯ç®—æ³•ç®€è¿°</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Algorithm/Maximum-entropy_Markov_model.html">7. æœ€å¤§ç†µé©¬å°”å¯å¤«æ¨¡å‹ MEMMï¼ˆMaximum-entropy Markov modelï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Algorithm/Maximum_Entropy.html">8. æœ€å¤§ç†µæ¨¡å‹ MEï¼ˆMaximum Entropyï¼‰</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Algorithm/Statistical_Model.html">9. ç»Ÿè®¡æ¨¡å‹</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Algorithm/Viterbi.html">10. Viterbi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Algorithm/index.html">11. ç®—æ³•æ±‡æ€»</a></li>
<li class="toctree-l1"><a class="reference internal" href="../awesome/Awesome-Chinese-NLP.html">12. awesome-chinese-nlp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../awesome/index.html">13. awesome-nlp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../awesome/multi-language.html">14. å…¶ä»–è¯­è¨€</a></li>
<li class="toctree-l1"><a class="reference internal" href="../awesome/techniques.html">15. æŠ€æœ¯</a></li>
<li class="toctree-l1"><a class="reference internal" href="../awesome/tutorials.html">16. æ•™ç¨‹</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Cloud/aliyun.html">17. é˜¿é‡Œäº‘è‡ªç„¶è¯­è¨€å¤„ç†</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Cloud/pai.html">18. é˜¿é‡Œæœºå™¨å­¦ä¹ å¹³å° PAI 3.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Cloud/ç™¾åº¦AI.html">19. ç™¾åº¦ AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/BERT/FAQ.html">20. å¸¸é—®é—®é¢˜</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/BERT/Fine-tuning_with_BERT.html">21. ä½¿ç”¨ BERT è¿›è¡Œå¾®è°ƒ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/BERT/Pre-trained_models.html">22. é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/BERT/Pre-training_with_BERT.html">23. ä½¿ç”¨ BERT è¿›è¡Œé¢„è®­ç»ƒ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/BERT/Using_BERT_in_Colab.html">24. åœ¨ Colab ä¸­ä½¿ç”¨ BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/BERT/Using_BERT_to_extract_fixed_feature_vectors.html">25. ä½¿ç”¨ BERT æå–å›ºå®šçš„ç‰¹å¾å‘é‡ (åƒ ELMo)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/BERT/What_is_BERT.html">26. ä»€ä¹ˆæ˜¯ BERTï¼Ÿ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/BERT/index.html">27. BERT å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/BERT/model.html">28. æ¨¡å‹</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/Knowledge_Graph/Agricultural_Knowledge_Graph.html">29. å†œä¸šçŸ¥è¯†å›¾è°±(AgriKG)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/Knowledge_Graph/ChineseNLPCorpus.html">30. Chinese NLP Corpus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/Knowledge_Graph/cnSchema.html">31. cnSchema</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/Knowledge_Graph/index.html">32. çŸ¥è¯†å›¾è°±</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/Knowledge_Graph/openkg.html">33. openkg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/regulation/LabelStyle.html">34. ç°ä»£æ±‰è¯­è¯­æ–™åº“åŠ å·¥è§„èŒƒ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/regulation/index.html">35. æ ‡æ³¨è§„èŒƒ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/regulation/nation.html">36. ä¿¡æ¯å¤„ç†ç”¨ç°ä»£æ±‰è¯­è¯ç±»æ ‡è®°è§„èŒƒ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/regulation/nlpir.html">37. è®¡ç®—æ‰€æ±‰è¯­è¯æ€§æ ‡è®°é›†</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/GlobalWordNetAssociation.html">38. å…¨çƒ WordNet åä¼š</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/HowNet.html">39. çŸ¥ç½‘</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/Schema.html">40. Schema</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/aihanyu.html">41. çˆ±æ±‰è¯­è¯­æ–™åº“</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/cow.html">42. Chinese Open Wordnet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/csdn.html">43. CSDN ä¸‹è½½</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/dianchacha.html">44. åº—æŸ¥æŸ¥æ•°æ®</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/funNLP.html">45. funNLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/index.html">46. è¯­æ–™åº“</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/nlp-datasets.html">47. nlp-datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/pku-opendata.html">48. åŒ—äº¬å¤§å­¦å¼€å‘æ•°æ®ç ”ç©¶å¹³å°</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/wikipedia.html">49. ç»´åŸºç™¾ç§‘è¯­æ–™åº“</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Corpus/wordnet.html">50. WordNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="FoolNLTK/index.html">51. FoolNLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="FoolNLTK/train.html">52. train</a></li>
<li class="toctree-l1"><a class="reference internal" href="JieBa/Jieba.html">53. JieBa</a></li>
<li class="toctree-l1"><a class="reference internal" href="JieBa/JiebaCpp.html">54. CppJieba</a></li>
<li class="toctree-l1"><a class="reference internal" href="JieBa/JiebaNode.html">55. NodeJieba</a></li>
<li class="toctree-l1"><a class="reference internal" href="HanLP.html">56. HanLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="Jcseg.html">57. Jcseg logo</a></li>
<li class="toctree-l1"><a class="reference internal" href="Jiagu.html">58. Jiagu</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">59. Keras</a></li>
<li class="toctree-l1"><a class="reference internal" href="#x-train-and-y-train-are-numpy-arrays-just-like-in-the-scikit-learn-api">60. x_train and y_train are Numpy arrays â€“just like in the Scikit-Learn API.</a></li>
<li class="toctree-l1"><a class="reference internal" href="PyTorch.html">61. PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="SnowNLP.html">62. SnowNLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="SpaCy.html">63. spacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="StanfordNLP.html">64. æ–¯å¦ç¦-StanfordNLP</a></li>
<li class="toctree-l1"><a class="reference internal" href="THULAC.html">65. æ¸…å-THULAC</a></li>
<li class="toctree-l1"><a class="reference internal" href="TensorFlow.html">66. TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="ansj_seg.html">67. Ansj ä¸­æ–‡åˆ†è¯</a></li>
<li class="toctree-l1"><a class="reference internal" href="awesome.html">68. ğŸ‘ğŸ» è¡¨åº“</a></li>
<li class="toctree-l1"><a class="reference internal" href="bosonnlp.html">69. ç»æ£®æ•°æ®</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html">70. å¸¸ç”¨åˆ†è¯å·¥å…·åŒ…</a></li>
<li class="toctree-l1"><a class="reference internal" href="ltp.html">71. å“ˆå·¥å¤§-LTP</a></li>
<li class="toctree-l1"><a class="reference internal" href="nlpair-ictclas.html">72. ä¸­ç§‘é™¢-NLPIR</a></li>
<li class="toctree-l1"><a class="reference internal" href="nltk.html">73. NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="pkuseg.html">74. åŒ—å¤§-pkuseg</a></li>
<li class="toctree-l1"><a class="reference internal" href="scikit-learn.html">75. scikit-learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="sego.html">76. sego</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Online/index.html">77. åœ¨çº¿åˆ†æå·¥å…·</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Paper/2018-nlp.html">78. 2018 å¹´ï¼ŒNLP ç ”ç©¶ä¸åº”ç”¨è¿›å±•åˆ°ä»€ä¹ˆæ°´å¹³äº†ï¼Ÿ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Paper/bert-jiqizhixin.html">79. è°·æ­Œç»ˆäºå¼€æº BERT ä»£ç ï¼š3 äº¿å‚æ•°é‡ï¼Œæœºå™¨ä¹‹å¿ƒå…¨é¢è§£è¯»</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Paper/chinese-segmenter.html">80. ç»†è¯´ä¸­æ–‡åˆ†è¯</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Paper/index.html">81. è®ºæ–‡ || æ–‡ç« </a></li>
<li class="toctree-l1"><a class="reference internal" href="../Paper/milestone.html">82. ä¸€æ–‡çœ‹æ‡‚ NLP ç¥ç»ç½‘ç»œå‘å±•å†å²ä¸­æœ€é‡è¦çš„ 8 ä¸ªé‡Œç¨‹ç¢‘</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Paper/nlp-gather.html">83. è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çŸ¥è¯†ç»“æ„æ€»ç»“</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Paper/nlp.ict.ac.cn.html">84. ä¸­å›½ç§‘å­¦é™¢è®¡ç®—æŠ€æœ¯ç ”ç©¶æ‰€è‡ªç„¶è¯­è¨€å¤„ç†ç ”ç©¶ç»„</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensitive-word/fastscan.html">85. FastScan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensitive-word/index.html">86. æ•æ„Ÿè¯</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">87. æœ¯è¯­è¡¨</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../contents.html">nlp-docs</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../contents.html">Docs</a> &raquo;</li>
        
      <li>59. Keras</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/Librariy/Keras.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="keras">
<h1>59. Keras<a class="headerlink" href="#keras" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h1>
<p>The Python Deep Learning library</p>
<p>You have just found Keras. Keras is a high-level neural networks API,
written in Python and capable of running on top of TensorFlow, CNTK, or
Theano. It was developed with a focus on enabling fast experimentation.
Being able to go from idea to result with the least possible delay is
key to doing good research.</p>
<p>Use Keras if you need a deep learning library that:</p>
<p>Allows for easy and fast prototyping (through user friendliness,
modularity, and extensibility). Supports both convolutional networks and
recurrent networks, as well as combinations of the two. Runs seamlessly
on CPU and GPU. Read the documentation at Keras.io.</p>
<p>Keras is compatible with: Python 2.7-3.6.</p>
<p>Guiding principles User friendliness. Keras is an API designed for human
beings, not machines. It puts user experience front and center. Keras
follows best practices for reducing cognitive load: it offers consistent
&amp; simple APIs, it minimizes the number of user actions required for
common use cases, and it provides clear and actionable feedback upon
user error.</p>
<p>Modularity. A model is understood as a sequence or a graph of
standalone, fully configurable modules that can be plugged together with
as few restrictions as possible. In particular, neural layers, cost
functions, optimizers, initialization schemes, activation functions and
regularization schemes are all standalone modules that you can combine
to create new models.</p>
<p>Easy extensibility. New modules are simple to add (as new classes and
functions), and existing modules provide ample examples. To be able to
easily create new modules allows for total expressiveness, making Keras
suitable for advanced research.</p>
<p>Work with Python. No separate models configuration files in a
declarative format. Models are described in Python code, which is
compact, easier to debug, and allows for ease of extensibility.</p>
<p>Getting started: 30 seconds to Keras The core data structure of Keras is
a model, a way to organize layers. The simplest type of model is the
Sequential model, a linear stack of layers. For more complex
architectures, you should use the Keras functional API, which allows to
build arbitrary graphs of layers.</p>
<p>Here is the Sequential model:</p>
<p>from keras.models import Sequential</p>
<p>model = Sequential() Stacking layers is as easy as .add():</p>
<p>from keras.layers import Dense</p>
<p>model.add(Dense(units=64, activation=â€˜reluâ€™, input_dim=100))
model.add(Dense(units=10, activation=â€˜softmaxâ€™)) Once your model looks
good, configure its learning process with .compile():</p>
<p>model.compile(loss=â€˜categorical_crossentropyâ€™, optimizer=â€˜sgdâ€™,
metrics=[â€˜accuracyâ€™]) If you need to, you can further configure your
optimizer. A core principle of Keras is to make things reasonably
simple, while allowing the user to be fully in control when they need to
(the ultimate control being the easy extensibility of the source code).</p>
<p>model.compile(loss=keras.losses.categorical_crossentropy,
optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))
You can now iterate on your training data in batches:</p>
</div>
<div class="section" id="x-train-and-y-train-are-numpy-arrays-just-like-in-the-scikit-learn-api">
<h1>60. x_train and y_train are Numpy arrays â€“just like in the Scikit-Learn API.<a class="headerlink" href="#x-train-and-y-train-are-numpy-arrays-just-like-in-the-scikit-learn-api" title="æ°¸ä¹…é“¾æ¥è‡³æ ‡é¢˜">Â¶</a></h1>
<p>model.fit(x_train, y_train, epochs=5, batch_size=32) Alternatively, you
can feed batches to your model manually:</p>
<p>model.train_on_batch(x_batch, y_batch) Evaluate your performance in one
line:</p>
<p>loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128) Or
generate predictions on new data:</p>
<p>classes = model.predict(x_test, batch_size=128) Building a question
answering system, an image classification model, a Neural Turing
Machine, or any other model is just as fast. The ideas behind deep
learning are simple, so why should their implementation be painful?</p>
<p>For a more in-depth tutorial about Keras, you can check out:</p>
<p>Getting started with the Sequential model Getting started with the
functional API In the examples folder of the repository, you will find
more advanced models: question-answering with memory networks, text
generation with stacked LSTMs, etc.</p>
<p>Installation Before installing Keras, please install one of its backend
engines: TensorFlow, Theano, or CNTK. We recommend the TensorFlow
backend.</p>
<p>TensorFlow installation instructions. Theano installation instructions.
CNTK installation instructions. You may also consider installing the
following optional dependencies:</p>
<p>cuDNN (recommended if you plan on running Keras on GPU). HDF5 and h5py
(required if you plan on saving Keras models to disk). graphviz and
pydot (used by visualization utilities to plot model graphs). Then, you
can install Keras itself. There are two ways to install Keras:</p>
<p>Install Keras from PyPI (recommended): sudo pip install keras If you are
using a virtualenv, you may want to avoid using sudo:</p>
<p>pip install keras Alternatively: install Keras from the GitHub source:
First, clone Keras using git:</p>
<p>git clone <a class="reference external" href="https://github.com/keras-team/keras.git">https://github.com/keras-team/keras.git</a> Then, cd to the Keras
folder and run the install command:</p>
<p>cd keras sudo python setup.py install Configuring your Keras backend By
default, Keras will use TensorFlow as its tensor manipulation library.
Follow these instructions to configure the Keras backend.</p>
<p>Support You can ask questions and join the development discussion:</p>
<p>On the Keras Google group. On the Keras Slack channel. Use this link to
request an invitation to the channel. You can also post bug reports and
feature requests (only) in GitHub issues. Make sure to read our
guidelines first.</p>
<p>Why this name, Keras? Keras (ÎºÎ­ÏÎ±Ï‚) means horn in Greek. It is a
reference to a literary image from ancient Greek and Latin literature,
first found in the Odyssey, where dream spirits (Oneiroi, singular
Oneiros) are divided between those who deceive men with false visions,
who arrive to Earth through a gate of ivory, and those who announce a
future that will come to pass, who arrive through a gate of horn. Itâ€™s a
play on the words ÎºÎ­ÏÎ±Ï‚ (horn) / ÎºÏÎ±Î¯Î½Ï‰ (fulfill), and á¼Î»Î­Ï†Î±Ï‚ (ivory) /
á¼Î»ÎµÏ†Î±Î¯ÏÎ¿Î¼Î±Î¹ (deceive).</p>
<p>Keras was initially developed as part of the research effort of project
ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating
System).</p>
<p>â€œOneiroi are beyond our unravelling â€“who can be sure what tale they
tell? Not all that men look for comes to pass. Two gates there are that
give passage to fleeting Oneiroi; one is made of horn, one of ivory. The
Oneiroi that pass through sawn ivory are deceitful, bearing a message
that will not be fulfilled; those that come out through polished horn
have truth behind them, to be accomplished for men who see them.â€ Homer,
Odyssey 19. 562 ff (Shewring translation).</p>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="PyTorch.html" class="btn btn-neutral float-right" title="61. PyTorch" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Jiagu.html" class="btn btn-neutral float-left" title="58. Jiagu" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Nosy

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>