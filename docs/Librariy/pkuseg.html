

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-CN" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-CN" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>北大-pkuseg &mdash; nlp-docs v2019.03.19 文档</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script type="text/javascript" src="../_static/translations.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../contents.html" class="icon icon-home"> nlp-docs
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">自然语言处理</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Author/index.html">自然语言处理作者</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Algorithm/index.html">算法汇总</a></li>
<li class="toctree-l1"><a class="reference internal" href="../awesome/index.html">awesome-nlp</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html">常用分词工具包</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Paper/index.html">论文 || 文章</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../contents.html">nlp-docs</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../contents.html">Docs</a> &raquo;</li>
        
      <li>北大-pkuseg</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/Librariy/pkuseg.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pkuseg">
<h1>北大-pkuseg<a class="headerlink" href="#pkuseg" title="永久链接至标题">¶</a></h1>
<p>一个多领域中文分词工具包</p>
<p><a class="reference external" href="https://github.com/lancopku/pkuseg-python">pkuseg</a>
简单易用，支持细分领域分词，有效提升了分词准确度。</p>
<div class="section" id="id1">
<h2>主要亮点<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h2>
<p>pkuseg 具有如下几个特点：</p>
<ol class="arabic simple">
<li><p>多领域分词。不同于以往的通用中文分词工具，此工具包同时致力于为不同领域的数据提供个性化的预训练模型。根据待分词文本的领域特点，用户可以自由地选择不同的模型。
我们目前支持了新闻领域，网络领域，医药领域，旅游领域，以及混合领域的分词预训练模型。在使用中，如果用户明确待分词的领域，可加载对应的模型进行分词。如果用户无法确定具体领域，推荐使用在混合领域上训练的通用模型。各领域分词样例可参考
<a class="reference external" href="https://github.com/lancopku/pkuseg-python/blob/master/example.txt">example.txt</a>。</p></li>
<li><p>更高的分词准确率。相比于其他的分词工具包，当使用相同的训练数据和测试数据，pkuseg
可以取得更高的分词准确率。</p></li>
<li><p>支持用户自训练模型。支持用户使用全新的标注数据进行训练。</p></li>
<li><p>支持词性标注。</p></li>
</ol>
</div>
<div class="section" id="id2">
<h2>编译和安装<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<ul>
<li><p>目前<strong>仅支持 python3</strong></p></li>
<li><p>新版本发布：2019-1-23</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- 修改了词典处理方法，扩充了词典，分词效果有提升
- **效率进行了优化，测试速度较之前版本提升 9 倍左右**
- 增加了在大规模混合数据集训练的通用模型，并将其设为默认使用模型
</pre></div>
</div>
</li>
<li><p>新版本发布：2019-1-30</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- 支持 fine-tune 训练（从预加载的模型继续训练），支持设定训练轮数
</pre></div>
</div>
</li>
<li><p>新版本发布：2019-2-20</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>- **支持词性标注，增加了医疗、旅游细领域模型**
</pre></div>
</div>
</li>
<li><p><strong>为了获得好的效果和速度，强烈建议大家通过 pip install
更新到目前的最新版本</strong></p></li>
</ul>
<p>安装</p>
<ol class="arabic">
<li><p>通过 PyPI 安装(自带模型文件)：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>pip3 install pkuseg
<span class="c1"># 之后通过import pkuseg来引用</span>
<span class="c1"># 建议更新到最新版本以获得更好的开箱体验：</span>
pip3 install -U pkuseg
</pre></div>
</div>
</li>
<li><p>如果 PyPI 官方源下载速度不理想，建议使用镜像源，比如：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="c1">#初次安装：</span>
pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple pkuseg
<span class="c1">#更新：</span>
pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple -U pkuseg
</pre></div>
</div>
</li>
<li><p>如果不使用 pip 安装方式，选择从 GitHub 下载，可运行以下命令安装：</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python setup.py build_ext -i
</pre></div>
</div>
<p>GitHub
的代码并不包括预训练模型，因此需要用户自行下载或训练模型，预训练模型可详见<a class="reference external" href="https://github.com/lancopku/pkuseg-python/releases">release</a>。使用时需设定“model_name”为模型文件。</p>
</li>
</ol>
<p>注意：<strong>安装方式 1 和 2 目前仅支持 linux(ubuntu)、mac、windows 64 位的
python3 版本</strong>。如果非以上系统，请使用安装方式 3 进行本地编译安装。</p>
</div>
<div class="section" id="id3">
<h2>使用方式<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h2>
<div class="section" id="id4">
<h3>代码示例<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h3>
<p>以下代码示例适用于 python 交互式环境。</p>
<p>代码示例
1：使用默认配置进行分词（<strong>如果用户无法确定分词领域，推荐使用默认模型分词</strong>）</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pkuseg</span>

<span class="n">seg</span> <span class="o">=</span> <span class="n">pkuseg</span><span class="o">.</span><span class="n">pkuseg</span><span class="p">()</span>           <span class="c1"># 以默认配置加载模型</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">seg</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="s1">&#39;我爱北京天安门&#39;</span><span class="p">)</span>  <span class="c1"># 进行分词</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<p>代码示例
2：细领域分词（<strong>如果用户明确分词领域，推荐使用细领域模型分词</strong>）</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pkuseg</span>

<span class="n">seg</span> <span class="o">=</span> <span class="n">pkuseg</span><span class="o">.</span><span class="n">pkuseg</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;medicine&#39;</span><span class="p">)</span>  <span class="c1"># 程序会自动下载所对应的细领域模型</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">seg</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="s1">&#39;我爱北京天安门&#39;</span><span class="p">)</span>              <span class="c1"># 进行分词</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<p>代码示例 3：分词同时进行词性标注，各词性标签的详细含义可参考
<a class="reference external" href="https://github.com/lancopku/pkuseg-python/blob/master/tags.txt">tags.txt</a></p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pkuseg</span>

<span class="n">seg</span> <span class="o">=</span> <span class="n">pkuseg</span><span class="o">.</span><span class="n">pkuseg</span><span class="p">(</span><span class="n">postag</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># 开启词性标注功能</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">seg</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="s1">&#39;我爱北京天安门&#39;</span><span class="p">)</span>    <span class="c1"># 进行分词和词性标注</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<p>代码示例 4：对文件分词</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pkuseg</span>

<span class="c1"># 对input.txt的文件分词输出到output.txt中</span>
<span class="c1"># 开20个进程</span>
<span class="n">pkuseg</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="s1">&#39;input.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;output.txt&#39;</span><span class="p">,</span> <span class="n">nthread</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
<p>代码示例 5：额外使用用户自定义词典</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pkuseg</span>

<span class="n">seg</span> <span class="o">=</span> <span class="n">pkuseg</span><span class="o">.</span><span class="n">pkuseg</span><span class="p">(</span><span class="n">user_dict</span><span class="o">=</span><span class="s1">&#39;my_dict.txt&#39;</span><span class="p">)</span>  <span class="c1"># 给定用户词典为当前目录下的&quot;my_dict.txt&quot;</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">seg</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="s1">&#39;我爱北京天安门&#39;</span><span class="p">)</span>                <span class="c1"># 进行分词</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<p>代码示例 6：使用自训练模型分词（以 CTB8 模型为例）</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pkuseg</span>

<span class="n">seg</span> <span class="o">=</span> <span class="n">pkuseg</span><span class="o">.</span><span class="n">pkuseg</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;./ctb8&#39;</span><span class="p">)</span>  <span class="c1"># 假设用户已经下载好了ctb8的模型并放在了&#39;./ctb8&#39;目录下，通过设置model_name加载该模型</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">seg</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="s1">&#39;我爱北京天安门&#39;</span><span class="p">)</span>            <span class="c1"># 进行分词</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<p>代码示例 7：训练新模型 （模型随机初始化）</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pkuseg</span>

<span class="c1"># 训练文件为&#39;msr_training.utf8&#39;</span>
<span class="c1"># 测试文件为&#39;msr_test_gold.utf8&#39;</span>
<span class="c1"># 训练好的模型存到&#39;./models&#39;目录下</span>
<span class="c1"># 训练模式下会保存最后一轮模型作为最终模型</span>
<span class="c1"># 目前仅支持utf-8编码，训练集和测试集要求所有单词以单个或多个空格分开</span>
<span class="n">pkuseg</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="s1">&#39;msr_training.utf8&#39;</span><span class="p">,</span> <span class="s1">&#39;msr_test_gold.utf8&#39;</span><span class="p">,</span> <span class="s1">&#39;./models&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>代码示例 8：fine-tune 训练（从预加载的模型继续训练）</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pkuseg</span>

<span class="c1"># 训练文件为&#39;train.txt&#39;</span>
<span class="c1"># 测试文件为&#39;test.txt&#39;</span>
<span class="c1"># 加载&#39;./pretrained&#39;目录下的模型，训练好的模型保存在&#39;./models&#39;，训练10轮</span>
<span class="n">pkuseg</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="s1">&#39;train.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;test.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;./models&#39;</span><span class="p">,</span> <span class="n">train_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">init_model</span><span class="o">=</span><span class="s1">&#39;./pretrained&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id5">
<h3>参数说明<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h3>
<p>模型配置</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>pkuseg.pkuseg(model_name = &quot;default&quot;, user_dict = &quot;default&quot;, postag = False)
    model_name      模型路径。
                    &quot;default&quot;，默认参数，表示使用我们预训练好的混合领域模型(仅对pip下载的用户)。
                &quot;news&quot;, 使用新闻领域模型。
                &quot;web&quot;, 使用网络领域模型。
                &quot;medicine&quot;, 使用医药领域模型。
                &quot;tourism&quot;, 使用旅游领域模型。
                    model_path, 从用户指定路径加载模型。
    user_dict       设置用户词典。
                &quot;default&quot;, 默认参数，使用我们提供的词典。
                None, 不使用词典。
                dict_path, 在使用默认词典的同时会额外使用用户自定义词典，可以填自己的用户词典的路径，词典格式为一行一个词。
    postag              是否进行词性分析。
                False, 默认参数，只进行分词，不进行词性标注。
                True, 会在分词的同时进行词性标注。
</pre></div>
</div>
<p>对文件进行分词</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>pkuseg.test(readFile, outputFile, model_name = &quot;default&quot;, user_dict = &quot;default&quot;, postag = False, nthread = 10)
    readFile        输入文件路径。
    outputFile      输出文件路径。
    model_name      模型路径。同pkuseg.pkuseg
    user_dict       设置用户词典。同pkuseg.pkuseg
    postag          设置是否开启词性分析功能。同pkuseg.pkuseg
    nthread         测试时开的进程数。
</pre></div>
</div>
<p>模型训练</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>pkuseg.train(trainFile, testFile, savedir, train_iter = 20, init_model = None)
    trainFile       训练文件路径。
    testFile        测试文件路径。
    savedir         训练模型的保存路径。
    train_iter      训练轮数。
    init_model      初始化模型，默认为None表示使用默认初始化，用户可以填自己想要初始化的模型的路径如init_model=&#39;./models/&#39;。
</pre></div>
</div>
</div>
<div class="section" id="id6">
<h3>多进程分词<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h3>
<p>当将以上代码示例置于文件中运行时，如涉及多进程功能，请务必使用<code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">__name__</span> <span class="pre">==</span> <span class="pre">'__main__'</span></code>保护全局语句，如：
mp.py 文件</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pkuseg</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">pkuseg</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="s1">&#39;input.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;output.txt&#39;</span><span class="p">,</span> <span class="n">nthread</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">pkuseg</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="s1">&#39;msr_training.utf8&#39;</span><span class="p">,</span> <span class="s1">&#39;msr_test_gold.utf8&#39;</span><span class="p">,</span> <span class="s1">&#39;./models&#39;</span><span class="p">,</span> <span class="n">nthread</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
<p>运行</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python3</span> <span class="n">mp</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p>详见<a class="reference external" href="https://github.com/lancopku/pkuseg-python/wiki#3-无法使用多进程分词和训练功能提示runtimeerror和brokenpipeerror">无法使用多进程分词和训练功能，提示 RuntimeError 和
BrokenPipeError</a>。</p>
<p><strong>在 Windows
平台上，请当文件足够大时再使用多进程分词功能</strong>，详见<a class="reference external" href="https://github.com/lancopku/pkuseg-python/wiki#9-关于多进程速度问题">关于多进程速度问题</a>。</p>
</div>
</div>
<div class="section" id="id7">
<h2>预训练模型<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h2>
<p>从 pip 安装的用户在使用细领域分词功能时，只需要设置 model_name
字段为对应的领域即可，会自动下载对应的细领域模型。</p>
<p>从 github 下载的用户则需要自己下载对应的预训练模型，并设置 model_name
字段为预训练模型路径。预训练模型可以在<a class="reference external" href="https://github.com/lancopku/pkuseg-python/releases">release</a>部分下载。以下是对预训练模型的说明：</p>
<ul class="simple">
<li><p><strong>news</strong>: 在 MSRA（新闻语料）上训练的模型。</p></li>
<li><p><strong>web</strong>: 在微博（网络文本语料）上训练的模型。</p></li>
<li><p><strong>medicine</strong>: 在医药领域上训练的模型。</p></li>
<li><p><strong>tourism</strong>: 在旅游领域上训练的模型。</p></li>
<li><p><strong>mixed</strong>: 混合数据集训练的通用模型。随 pip 包附带的是此模型。</p></li>
</ul>
<p>欢迎更多用户可以分享自己训练好的细分领域模型。</p>
</div>
<div class="section" id="id8">
<h2>各类分词工具包的性能对比<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h2>
<p>我们选择 jieba、THULAC 等国内代表分词工具包与 pkuseg 做性能比较。</p>
<p>考虑到 jieba 分词和 THULAC
工具包等并没有提供细领域的预训练模型，为了便于比较，我们重新使用它们提供的训练接口在细领域的数据集上进行训练，用训练得到的模型进行中文分词。</p>
<p>我们选择 Linux
作为测试环境，在新闻数据(MSRA)、混合型文本(CTB8)、网络文本(WEIBO)数据上对不同工具包进行了准确率测试。我们使用了第二届国际汉语分词评测比赛提供的分词评价脚本。其中
MSRA 与 WEIBO 使用标准训练集测试集划分，CTB8
采用随机划分。对于不同的分词工具包，训练测试数据的划分都是一致的；<strong>即所有的分词工具包都在相同的训练集上训练，在相同的测试集上测试</strong>。对于所有数据集，pkuseg
使用了不使用词典的训练和测试接口。以下是 pkuseg 训练和测试代码示例:</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">pkuseg</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="s1">&#39;msr_training.utf8&#39;</span><span class="p">,</span> <span class="s1">&#39;msr_test_gold.utf8&#39;</span><span class="p">,</span> <span class="s1">&#39;./models&#39;</span><span class="p">)</span>
<span class="n">pkuseg</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="s1">&#39;msr_test.raw&#39;</span><span class="p">,</span> <span class="s1">&#39;output.txt&#39;</span><span class="p">,</span> <span class="n">user_dict</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="id9">
<h3>细领域训练及测试结果<a class="headerlink" href="#id9" title="永久链接至标题">¶</a></h3>
<p>以下是在不同数据集上的对比结果：</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 21%" />
<col style="width: 29%" />
<col style="width: 21%" />
<col style="width: 29%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>MSRA</p></th>
<th class="head"><p>Precision</p></th>
<th class="head"><p>Recall</p></th>
<th class="head"><p>F-score</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>jieba</p></td>
<td><p>87.01</p></td>
<td><p>89.88</p></td>
<td><p>88.42</p></td>
</tr>
<tr class="row-odd"><td><p>THULAC</p></td>
<td><p>95.60</p></td>
<td><p>95.91</p></td>
<td><p>95.71</p></td>
</tr>
<tr class="row-even"><td><p>pkuseg</p></td>
<td><p>96.94</p></td>
<td><p>96.81</p></td>
<td><p><strong>96.88</strong></p></td>
</tr>
</tbody>
</table>
<table class="docutils align-center">
<colgroup>
<col style="width: 21%" />
<col style="width: 29%" />
<col style="width: 21%" />
<col style="width: 29%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>WEIBO</p></th>
<th class="head"><p>Precision</p></th>
<th class="head"><p>Recall</p></th>
<th class="head"><p>F-score</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>jieba</p></td>
<td><p>87.79</p></td>
<td><p>87.54</p></td>
<td><p>87.66</p></td>
</tr>
<tr class="row-odd"><td><p>THULAC</p></td>
<td><p>93.40</p></td>
<td><p>92.40</p></td>
<td><p>92.87</p></td>
</tr>
<tr class="row-even"><td><p>pkuseg</p></td>
<td><p>93.78</p></td>
<td><p>94.65</p></td>
<td><p><strong>94.21</strong></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id10">
<h3>默认模型在不同领域的测试效果<a class="headerlink" href="#id10" title="永久链接至标题">¶</a></h3>
<p>考虑到很多用户在尝试分词工具的时候，大多数时候会使用工具包自带模型测试。为了直接对比“初始”性能，我们也比较了各个工具包的默认模型在不同领域的测试效果。请注意，这样的比较只是为了说明默认情况下的效果，并不一定是公平的。</p>
<table class="docutils align-center">
<colgroup>
<col style="width: 18%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 26%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Default</p></th>
<th class="head"><p>MSRA</p></th>
<th class="head"><p>CTB8</p></th>
<th class="head"><p>PKU</p></th>
<th class="head"><p>WEIBO</p></th>
<th class="head"><p>All Average</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>jieba</p></td>
<td><p>81.45</p></td>
<td><p>79.58</p></td>
<td><p>81.83</p></td>
<td><p>83.56</p></td>
<td><p>81.61</p></td>
</tr>
<tr class="row-odd"><td><p>THULAC</p></td>
<td><p>85.55</p></td>
<td><p>87.84</p></td>
<td><p>92.29</p></td>
<td><p>86.65</p></td>
<td><p>88.08</p></td>
</tr>
<tr class="row-even"><td><p>pkuseg</p></td>
<td><p>87.29</p></td>
<td><p>91.77</p></td>
<td><p>92.68</p></td>
<td><p>93.43</p></td>
<td><p><strong>91.29</strong></p></td>
</tr>
</tbody>
</table>
<p>其中，<code class="docutils literal notranslate"><span class="pre">All</span> <span class="pre">Average</span></code>显示的是在所有测试集上 F-score 的平均。</p>
<p>更多详细比较可参见<a class="reference external" href="https://github.com/lancopku/pkuseg-python/wiki/%E5%92%8C%E7%8E%B0%E6%9C%89%E5%B7%A5%E5%85%B7%E5%8C%85%E7%9A%84%E6%AF%94%E8%BE%83">和现有工具包的比较</a>。</p>
</div>
</div>
<div class="section" id="id11">
<h2>版本历史<a class="headerlink" href="#id11" title="永久链接至标题">¶</a></h2>
<ul class="simple">
<li><p>v0.0.11(2019-01-09)</p>
<ul>
<li><p>修订默认配置：CTB8 作为默认模型，不使用词典</p></li>
</ul>
</li>
<li><p>v0.0.14(2019-01-23)</p>
<ul>
<li><p>修改了词典处理方法，扩充了词典，分词效果有提升</p></li>
<li><p>效率进行了优化，测试速度较之前版本提升 9 倍左右</p></li>
<li><p>增加了在大规模混合数据集训练的通用模型，并将其设为默认使用模型</p></li>
</ul>
</li>
<li><p>v0.0.15(2019-01-30)</p>
<ul>
<li><p>支持 fine-tune 训练（从预加载的模型继续训练），支持设定训练轮数</p></li>
</ul>
</li>
<li><p>v0.0.18(2019-02-20)</p>
<ul>
<li><p>支持词性标注，增加了医疗、旅游两个细领域模型</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id12">
<h2>开源协议<a class="headerlink" href="#id12" title="永久链接至标题">¶</a></h2>
<ol class="arabic simple">
<li><p>本代码采用 MIT 许可证。</p></li>
<li><p>欢迎对该工具包提出任何宝贵意见和建议，请发邮件至
<a class="reference external" href="mailto:jingjingxu&#37;&#52;&#48;pku&#46;edu&#46;cn">jingjingxu<span>&#64;</span>pku<span>&#46;</span>edu<span>&#46;</span>cn</a>。</p></li>
</ol>
</div>
<div class="section" id="id13">
<h2>相关论文<a class="headerlink" href="#id13" title="永久链接至标题">¶</a></h2>
<p>该代码包主要基于以下科研论文，如使用了本工具，请引用以下论文：</p>
<ul class="simple">
<li><p>Xu Sun, Houfeng Wang, Wenjie Li. <a class="reference external" href="http://www.aclweb.org/anthology/P12-1027">Fast Online Training with
Frequency-Adaptive Learning Rates for Chinese Word Segmentation and
New Word Detection</a>.
ACL. 253–262. 2012</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@inproceedings</span><span class="p">{</span><span class="n">DBLP</span><span class="p">:</span><span class="n">conf</span><span class="o">/</span><span class="n">acl</span><span class="o">/</span><span class="n">SunWL12</span><span class="p">,</span>
<span class="n">author</span> <span class="o">=</span> <span class="p">{</span><span class="n">Xu</span> <span class="n">Sun</span> <span class="ow">and</span> <span class="n">Houfeng</span> <span class="n">Wang</span> <span class="ow">and</span> <span class="n">Wenjie</span> <span class="n">Li</span><span class="p">},</span>
<span class="n">title</span> <span class="o">=</span> <span class="p">{</span><span class="n">Fast</span> <span class="n">Online</span> <span class="n">Training</span> <span class="k">with</span> <span class="n">Frequency</span><span class="o">-</span><span class="n">Adaptive</span> <span class="n">Learning</span> <span class="n">Rates</span> <span class="k">for</span> <span class="n">Chinese</span> <span class="n">Word</span> <span class="n">Segmentation</span> <span class="ow">and</span> <span class="n">New</span> <span class="n">Word</span> <span class="n">Detection</span><span class="p">},</span>
<span class="n">booktitle</span> <span class="o">=</span> <span class="p">{</span><span class="n">The</span> <span class="mi">50</span><span class="n">th</span> <span class="n">Annual</span> <span class="n">Meeting</span> <span class="n">of</span> <span class="n">the</span> <span class="n">Association</span> <span class="k">for</span> <span class="n">Computational</span> <span class="n">Linguistics</span><span class="p">,</span> <span class="n">Proceedings</span> <span class="n">of</span> <span class="n">the</span> <span class="n">Conference</span><span class="p">,</span> <span class="n">July</span> <span class="mi">8</span><span class="o">-</span><span class="mi">14</span><span class="p">,</span> <span class="mi">2012</span><span class="p">,</span> <span class="n">Jeju</span> <span class="n">Island</span><span class="p">,</span> <span class="n">Korea</span><span class="o">-</span> <span class="n">Volume</span> <span class="mi">1</span><span class="p">:</span> <span class="n">Long</span> <span class="n">Papers</span><span class="p">},</span>
<span class="n">pages</span> <span class="o">=</span> <span class="p">{</span><span class="mi">253</span><span class="o">--</span><span class="mi">262</span><span class="p">},</span>
<span class="n">year</span> <span class="o">=</span> <span class="p">{</span><span class="mi">2012</span><span class="p">}}</span>
</pre></div>
</div>
</div>
<div class="section" id="id14">
<h2>常见问题及解答<a class="headerlink" href="#id14" title="永久链接至标题">¶</a></h2>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://github.com/lancopku/pkuseg-python/wiki/FAQ#1-为什么要发布pkuseg">为什么要发布
pkuseg？</a></p></li>
<li><p><a class="reference external" href="https://github.com/lancopku/pkuseg-python/wiki/FAQ#2-pkuseg使用了哪些技术">pkuseg
使用了哪些技术？</a></p></li>
<li><p><a class="reference external" href="https://github.com/lancopku/pkuseg-python/wiki/FAQ#3-无法使用多进程分词和训练功能提示runtimeerror和brokenpipeerror">无法使用多进程分词和训练功能，提示 RuntimeError 和
BrokenPipeError。</a></p></li>
<li><p><a class="reference external" href="https://github.com/lancopku/pkuseg-python/wiki/FAQ#4-是如何跟其它工具包在细领域数据上进行比较的">是如何跟其它工具包在细领域数据上进行比较的？</a></p></li>
<li><p><a class="reference external" href="https://github.com/lancopku/pkuseg-python/wiki/FAQ#5-在黑盒测试集上进行比较的话效果如何">在黑盒测试集上进行比较的话，效果如何？</a></p></li>
<li><p><a class="reference external" href="https://github.com/lancopku/pkuseg-python/wiki/FAQ#6-如果我不了解待分词语料的所属领域呢">如果我不了解待分词语料的所属领域呢？</a></p></li>
<li><p><a class="reference external" href="https://github.com/lancopku/pkuseg-python/wiki/FAQ#7-如何看待在一些特定样例上的分词结果">如何看待在一些特定样例上的分词结果？</a></p></li>
<li><p><a class="reference external" href="https://github.com/lancopku/pkuseg-python/wiki/FAQ#8-关于运行速度问题">关于运行速度问题？</a></p></li>
<li><p><a class="reference external" href="https://github.com/lancopku/pkuseg-python/wiki/FAQ#9-关于多进程速度问题">关于多进程速度问题？</a></p></li>
</ol>
</div>
<div class="section" id="id15">
<h2>作者<a class="headerlink" href="#id15" title="永久链接至标题">¶</a></h2>
<p>Ruixuan Luo （罗睿轩）, Jingjing Xu（许晶晶）, Xuancheng Ren（任宣丞）,
Yi Zhang（张艺）, Bingzhen Wei（位冰镇）， Xu Sun （孙栩）</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Nosy

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>